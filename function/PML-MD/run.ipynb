{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15629,"status":"ok","timestamp":1671502808904,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"},"user_tz":-540},"id":"_gPbR5TgSyPS","outputId":"3eec3a05-8556-4388-bd78-26e39f45fea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dboWTKluS6US","executionInfo":{"status":"ok","timestamp":1671502808904,"user_tz":-540,"elapsed":3,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}}},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/function/PML-MD\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qy6Cy5h7Su16","executionInfo":{"status":"error","timestamp":1671185351660,"user_tz":-540,"elapsed":344057,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"9ed272f0-a858-4969-b1d4-5e2b7ff100be"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","data=music_emotion/cv=0/p_noise=0/p_true=1/method=meta\n","\n","Batch: [0001/0500]  training loss: 1.5177  meta_loss: 1.9891  hLoss: 0.2305  rLoss: 0.3171  oError: 0.5991  conv: 0.4941  avgPre: 0.5189\n","Batch: [0002/0500]  training loss: 1.2481  meta_loss: 1.3391  hLoss: 0.2119  rLoss: 0.2937  oError: 0.5516  conv: 0.4605  avgPre: 0.5579\n","Batch: [0003/0500]  training loss: 1.1506  meta_loss: 1.2233  hLoss: 0.2152  rLoss: 0.2790  oError: 0.5077  conv: 0.4454  avgPre: 0.5837\n","Batch: [0004/0500]  training loss: 1.1052  meta_loss: 1.2149  hLoss: 0.2057  rLoss: 0.2735  oError: 0.5128  conv: 0.4375  avgPre: 0.5872\n","Batch: [0005/0500]  training loss: 1.0901  meta_loss: 1.3240  hLoss: 0.2101  rLoss: 0.2766  oError: 0.5106  conv: 0.4452  avgPre: 0.5771\n","Batch: [0006/0500]  training loss: 1.0690  meta_loss: 1.3412  hLoss: 0.2110  rLoss: 0.2707  oError: 0.4952  conv: 0.4396  avgPre: 0.5982\n","Batch: [0007/0500]  training loss: 1.0573  meta_loss: 1.2653  hLoss: 0.2084  rLoss: 0.2714  oError: 0.5011  conv: 0.4403  avgPre: 0.5874\n","Batch: [0008/0500]  training loss: 1.0412  meta_loss: 1.2704  hLoss: 0.2093  rLoss: 0.2643  oError: 0.4982  conv: 0.4299  avgPre: 0.5930\n","Batch: [0009/0500]  training loss: 1.0335  meta_loss: 1.2624  hLoss: 0.2072  rLoss: 0.2628  oError: 0.4952  conv: 0.4272  avgPre: 0.5953\n","Batch: [0010/0500]  training loss: 1.0275  meta_loss: 1.2766  hLoss: 0.2086  rLoss: 0.2691  oError: 0.5018  conv: 0.4385  avgPre: 0.5882\n","Batch: [0011/0500]  training loss: 1.0184  meta_loss: 1.2807  hLoss: 0.2076  rLoss: 0.2609  oError: 0.4996  conv: 0.4220  avgPre: 0.5970\n","Batch: [0012/0500]  training loss: 1.0125  meta_loss: 1.2913  hLoss: 0.2070  rLoss: 0.2611  oError: 0.4960  conv: 0.4267  avgPre: 0.5955\n","Batch: [0013/0500]  training loss: 1.0045  meta_loss: 1.2516  hLoss: 0.2114  rLoss: 0.2654  oError: 0.4909  conv: 0.4324  avgPre: 0.5941\n","Batch: [0014/0500]  training loss: 0.9979  meta_loss: 1.2719  hLoss: 0.2085  rLoss: 0.2632  oError: 0.4923  conv: 0.4269  avgPre: 0.5959\n","Batch: [0015/0500]  training loss: 0.9918  meta_loss: 1.2660  hLoss: 0.2095  rLoss: 0.2593  oError: 0.4938  conv: 0.4234  avgPre: 0.5975\n","Batch: [0016/0500]  training loss: 0.9815  meta_loss: 1.2320  hLoss: 0.2051  rLoss: 0.2799  oError: 0.4952  conv: 0.4467  avgPre: 0.5669\n","Batch: [0017/0500]  training loss: 0.9762  meta_loss: 1.3404  hLoss: 0.2061  rLoss: 0.2576  oError: 0.4843  conv: 0.4213  avgPre: 0.6020\n","Batch: [0018/0500]  training loss: 0.9788  meta_loss: 1.3646  hLoss: 0.2110  rLoss: 0.2565  oError: 0.4835  conv: 0.4200  avgPre: 0.6052\n","Batch: [0019/0500]  training loss: 0.9669  meta_loss: 1.3283  hLoss: 0.2152  rLoss: 0.2535  oError: 0.4674  conv: 0.4166  avgPre: 0.6150\n","Batch: [0020/0500]  training loss: 0.9591  meta_loss: 1.3298  hLoss: 0.2107  rLoss: 0.2519  oError: 0.4792  conv: 0.4203  avgPre: 0.6056\n","Batch: [0021/0500]  training loss: 0.9560  meta_loss: 1.3224  hLoss: 0.2085  rLoss: 0.2545  oError: 0.4828  conv: 0.4212  avgPre: 0.6043\n","Batch: [0022/0500]  training loss: 0.9519  meta_loss: 1.3010  hLoss: 0.2149  rLoss: 0.2584  oError: 0.4865  conv: 0.4263  avgPre: 0.5980\n","Batch: [0023/0500]  training loss: 0.9510  meta_loss: 1.3828  hLoss: 0.2127  rLoss: 0.2516  oError: 0.4726  conv: 0.4175  avgPre: 0.6085\n","Batch: [0024/0500]  training loss: 0.9448  meta_loss: 1.3105  hLoss: 0.2129  rLoss: 0.2520  oError: 0.4740  conv: 0.4232  avgPre: 0.6094\n","Batch: [0025/0500]  training loss: 0.9470  meta_loss: 1.3040  hLoss: 0.2066  rLoss: 0.2612  oError: 0.4960  conv: 0.4296  avgPre: 0.6010\n","Batch: [0026/0500]  training loss: 0.9446  meta_loss: 1.4092  hLoss: 0.2125  rLoss: 0.2543  oError: 0.4674  conv: 0.4229  avgPre: 0.6083\n","Batch: [0027/0500]  training loss: 0.9352  meta_loss: 1.2906  hLoss: 0.2086  rLoss: 0.2580  oError: 0.4762  conv: 0.4295  avgPre: 0.5971\n","Batch: [0028/0500]  training loss: 0.9311  meta_loss: 1.3116  hLoss: 0.2092  rLoss: 0.2508  oError: 0.4931  conv: 0.4148  avgPre: 0.6036\n","Batch: [0029/0500]  training loss: 0.9272  meta_loss: 1.2886  hLoss: 0.2078  rLoss: 0.2505  oError: 0.4850  conv: 0.4159  avgPre: 0.6066\n","Batch: [0030/0500]  training loss: 0.9251  meta_loss: 1.2868  hLoss: 0.2051  rLoss: 0.2513  oError: 0.5048  conv: 0.4178  avgPre: 0.5970\n","Batch: [0031/0500]  training loss: 0.9201  meta_loss: 1.2888  hLoss: 0.2088  rLoss: 0.2481  oError: 0.4996  conv: 0.4136  avgPre: 0.5999\n","Batch: [0032/0500]  training loss: 0.9214  meta_loss: 1.3010  hLoss: 0.2066  rLoss: 0.2580  oError: 0.5106  conv: 0.4287  avgPre: 0.5858\n","Batch: [0033/0500]  training loss: 0.9225  meta_loss: 1.3342  hLoss: 0.2056  rLoss: 0.2549  oError: 0.5048  conv: 0.4230  avgPre: 0.5930\n","Batch: [0034/0500]  training loss: 0.9169  meta_loss: 1.3211  hLoss: 0.2048  rLoss: 0.2499  oError: 0.4952  conv: 0.4180  avgPre: 0.5991\n","Batch: [0035/0500]  training loss: 0.9143  meta_loss: 1.3099  hLoss: 0.2076  rLoss: 0.2530  oError: 0.4945  conv: 0.4194  avgPre: 0.5988\n","Batch: [0036/0500]  training loss: 0.9135  meta_loss: 1.2932  hLoss: 0.2098  rLoss: 0.2492  oError: 0.4821  conv: 0.4137  avgPre: 0.6067\n","Batch: [0037/0500]  training loss: 0.9114  meta_loss: 1.2843  hLoss: 0.2094  rLoss: 0.2521  oError: 0.4865  conv: 0.4186  avgPre: 0.5991\n","Batch: [0038/0500]  training loss: 0.9073  meta_loss: 1.2832  hLoss: 0.2084  rLoss: 0.2514  oError: 0.4931  conv: 0.4167  avgPre: 0.5991\n","Batch: [0039/0500]  training loss: 0.9063  meta_loss: 1.3079  hLoss: 0.2096  rLoss: 0.2473  oError: 0.4696  conv: 0.4154  avgPre: 0.6094\n","Batch: [0040/0500]  training loss: 0.9044  meta_loss: 1.2171  hLoss: 0.2020  rLoss: 0.2578  oError: 0.4799  conv: 0.4256  avgPre: 0.6017\n","Batch: [0041/0500]  training loss: 0.9101  meta_loss: 1.3674  hLoss: 0.2121  rLoss: 0.2556  oError: 0.4601  conv: 0.4284  avgPre: 0.6058\n","Batch: [0042/0500]  training loss: 0.9097  meta_loss: 1.3173  hLoss: 0.2060  rLoss: 0.2473  oError: 0.5026  conv: 0.4124  avgPre: 0.5997\n","Batch: [0043/0500]  training loss: 0.9019  meta_loss: 1.3362  hLoss: 0.2080  rLoss: 0.2542  oError: 0.4857  conv: 0.4236  avgPre: 0.5970\n","Batch: [0044/0500]  training loss: 0.8945  meta_loss: 1.3035  hLoss: 0.2087  rLoss: 0.2469  oError: 0.4711  conv: 0.4103  avgPre: 0.6102\n","Batch: [0045/0500]  training loss: 0.8966  meta_loss: 1.3480  hLoss: 0.2112  rLoss: 0.2522  oError: 0.4733  conv: 0.4198  avgPre: 0.6050\n","Batch: [0046/0500]  training loss: 0.8946  meta_loss: 1.3468  hLoss: 0.2082  rLoss: 0.2477  oError: 0.4887  conv: 0.4148  avgPre: 0.6053\n","Batch: [0047/0500]  training loss: 0.8920  meta_loss: 1.2439  hLoss: 0.2048  rLoss: 0.2568  oError: 0.5048  conv: 0.4250  avgPre: 0.5892\n","Batch: [0048/0500]  training loss: 0.8885  meta_loss: 1.2563  hLoss: 0.2095  rLoss: 0.2497  oError: 0.4660  conv: 0.4193  avgPre: 0.6074\n","Batch: [0049/0500]  training loss: 0.8902  meta_loss: 1.3415  hLoss: 0.2097  rLoss: 0.2484  oError: 0.4660  conv: 0.4178  avgPre: 0.6091\n","Batch: [0050/0500]  training loss: 0.8853  meta_loss: 1.3555  hLoss: 0.2127  rLoss: 0.2407  oError: 0.4653  conv: 0.4111  avgPre: 0.6168\n","Batch: [0051/0500]  training loss: 0.8809  meta_loss: 1.2882  hLoss: 0.2125  rLoss: 0.2508  oError: 0.4601  conv: 0.4242  avgPre: 0.6030\n","Batch: [0052/0500]  training loss: 0.8847  meta_loss: 1.3472  hLoss: 0.2099  rLoss: 0.2443  oError: 0.4799  conv: 0.4083  avgPre: 0.6101\n","Batch: [0053/0500]  training loss: 0.8786  meta_loss: 1.2563  hLoss: 0.2056  rLoss: 0.2468  oError: 0.4872  conv: 0.4177  avgPre: 0.6005\n","Batch: [0054/0500]  training loss: 0.8810  meta_loss: 1.2885  hLoss: 0.2141  rLoss: 0.2426  oError: 0.4521  conv: 0.4130  avgPre: 0.6157\n","Batch: [0055/0500]  training loss: 0.8834  meta_loss: 1.3250  hLoss: 0.2067  rLoss: 0.2468  oError: 0.4901  conv: 0.4147  avgPre: 0.6028\n","Batch: [0056/0500]  training loss: 0.8800  meta_loss: 1.2469  hLoss: 0.2052  rLoss: 0.2439  oError: 0.4923  conv: 0.4104  avgPre: 0.6033\n","Batch: [0057/0500]  training loss: 0.8796  meta_loss: 1.3385  hLoss: 0.2077  rLoss: 0.2479  oError: 0.4938  conv: 0.4142  avgPre: 0.5979\n","Batch: [0058/0500]  training loss: 0.8728  meta_loss: 1.2689  hLoss: 0.2066  rLoss: 0.2476  oError: 0.4850  conv: 0.4152  avgPre: 0.6037\n","Batch: [0059/0500]  training loss: 0.8752  meta_loss: 1.2458  hLoss: 0.2151  rLoss: 0.2410  oError: 0.4411  conv: 0.4108  avgPre: 0.6227\n","Batch: [0060/0500]  training loss: 0.8766  meta_loss: 1.3301  hLoss: 0.2095  rLoss: 0.2406  oError: 0.4601  conv: 0.4075  avgPre: 0.6167\n","Batch: [0061/0500]  training loss: 0.8741  meta_loss: 1.2668  hLoss: 0.2040  rLoss: 0.2468  oError: 0.4579  conv: 0.4142  avgPre: 0.6111\n","Batch: [0062/0500]  training loss: 0.8743  meta_loss: 1.3635  hLoss: 0.2088  rLoss: 0.2483  oError: 0.4806  conv: 0.4174  avgPre: 0.6095\n","Batch: [0063/0500]  training loss: 0.8733  meta_loss: 1.3231  hLoss: 0.2093  rLoss: 0.2435  oError: 0.4528  conv: 0.4115  avgPre: 0.6168\n","Batch: [0064/0500]  training loss: 0.8669  meta_loss: 1.3051  hLoss: 0.2076  rLoss: 0.2451  oError: 0.4748  conv: 0.4145  avgPre: 0.6131\n","Batch: [0065/0500]  training loss: 0.8715  meta_loss: 1.3803  hLoss: 0.2084  rLoss: 0.2425  oError: 0.4594  conv: 0.4134  avgPre: 0.6162\n","Batch: [0066/0500]  training loss: 0.8626  meta_loss: 1.2356  hLoss: 0.2076  rLoss: 0.2444  oError: 0.4821  conv: 0.4129  avgPre: 0.6071\n","Batch: [0067/0500]  training loss: 0.8654  meta_loss: 1.2707  hLoss: 0.2063  rLoss: 0.2522  oError: 0.5004  conv: 0.4216  avgPre: 0.5916\n","Batch: [0068/0500]  training loss: 0.8638  meta_loss: 1.2789  hLoss: 0.2053  rLoss: 0.2462  oError: 0.4887  conv: 0.4133  avgPre: 0.6048\n","Batch: [0069/0500]  training loss: 0.8606  meta_loss: 1.2554  hLoss: 0.2092  rLoss: 0.2476  oError: 0.4440  conv: 0.4148  avgPre: 0.6193\n","Batch: [0070/0500]  training loss: 0.8592  meta_loss: 1.3466  hLoss: 0.2126  rLoss: 0.2419  oError: 0.4653  conv: 0.4092  avgPre: 0.6164\n","Batch: [0071/0500]  training loss: 0.8587  meta_loss: 1.2691  hLoss: 0.2113  rLoss: 0.2431  oError: 0.4704  conv: 0.4106  avgPre: 0.6126\n","Batch: [0072/0500]  training loss: 0.8625  meta_loss: 1.2974  hLoss: 0.2110  rLoss: 0.2425  oError: 0.4784  conv: 0.4081  avgPre: 0.6119\n","Batch: [0073/0500]  training loss: 0.8657  meta_loss: 1.3362  hLoss: 0.2118  rLoss: 0.2431  oError: 0.4514  conv: 0.4148  avgPre: 0.6180\n","Batch: [0074/0500]  training loss: 0.8584  meta_loss: 1.3041  hLoss: 0.2117  rLoss: 0.2414  oError: 0.4660  conv: 0.4086  avgPre: 0.6150\n","Batch: [0075/0500]  training loss: 0.8609  meta_loss: 1.2799  hLoss: 0.2068  rLoss: 0.2435  oError: 0.4777  conv: 0.4111  avgPre: 0.6094\n","Batch: [0076/0500]  training loss: 0.8597  meta_loss: 1.2561  hLoss: 0.2115  rLoss: 0.2374  oError: 0.4609  conv: 0.4059  avgPre: 0.6188\n","Batch: [0077/0500]  training loss: 0.8573  meta_loss: 1.2387  hLoss: 0.2113  rLoss: 0.2437  oError: 0.4733  conv: 0.4143  avgPre: 0.6097\n","Batch: [0078/0500]  training loss: 0.8591  meta_loss: 1.2287  hLoss: 0.2105  rLoss: 0.2442  oError: 0.4601  conv: 0.4146  avgPre: 0.6169\n","Batch: [0079/0500]  training loss: 0.8579  meta_loss: 1.2742  hLoss: 0.2072  rLoss: 0.2408  oError: 0.4916  conv: 0.4095  avgPre: 0.6074\n","Batch: [0080/0500]  training loss: 0.8549  meta_loss: 1.2895  hLoss: 0.2124  rLoss: 0.2415  oError: 0.4550  conv: 0.4086  avgPre: 0.6194\n","Batch: [0081/0500]  training loss: 0.8585  meta_loss: 1.3239  hLoss: 0.2048  rLoss: 0.2442  oError: 0.4726  conv: 0.4138  avgPre: 0.6087\n","Batch: [0082/0500]  training loss: 0.8663  meta_loss: 1.3160  hLoss: 0.2074  rLoss: 0.2405  oError: 0.4682  conv: 0.4111  avgPre: 0.6144\n","Batch: [0083/0500]  training loss: 0.8530  meta_loss: 1.2193  hLoss: 0.2037  rLoss: 0.2451  oError: 0.4850  conv: 0.4174  avgPre: 0.6041\n","Batch: [0084/0500]  training loss: 0.8563  meta_loss: 1.3334  hLoss: 0.2088  rLoss: 0.2423  oError: 0.4601  conv: 0.4066  avgPre: 0.6279\n","Batch: [0085/0500]  training loss: 0.8577  meta_loss: 1.2798  hLoss: 0.2057  rLoss: 0.2449  oError: 0.4901  conv: 0.4151  avgPre: 0.6037\n","Batch: [0086/0500]  training loss: 0.8570  meta_loss: 1.2784  hLoss: 0.2109  rLoss: 0.2395  oError: 0.4462  conv: 0.4093  avgPre: 0.6217\n","Batch: [0087/0500]  training loss: 0.8666  meta_loss: 1.3563  hLoss: 0.2118  rLoss: 0.2397  oError: 0.4367  conv: 0.4122  avgPre: 0.6224\n","Batch: [0088/0500]  training loss: 0.8661  meta_loss: 1.3758  hLoss: 0.2080  rLoss: 0.2383  oError: 0.4638  conv: 0.4093  avgPre: 0.6179\n","Batch: [0089/0500]  training loss: 0.8704  meta_loss: 1.3379  hLoss: 0.2056  rLoss: 0.2527  oError: 0.4974  conv: 0.4256  avgPre: 0.5922\n","Batch: [0090/0500]  training loss: 0.8837  meta_loss: 1.3833  hLoss: 0.2049  rLoss: 0.2496  oError: 0.4638  conv: 0.4210  avgPre: 0.6064\n","Batch: [0091/0500]  training loss: 0.8655  meta_loss: 1.3133  hLoss: 0.2122  rLoss: 0.2357  oError: 0.4236  conv: 0.4062  avgPre: 0.6330\n","Batch: [0092/0500]  training loss: 0.8601  meta_loss: 1.2403  hLoss: 0.2047  rLoss: 0.2477  oError: 0.5077  conv: 0.4205  avgPre: 0.5945\n","Batch: [0093/0500]  training loss: 0.8623  meta_loss: 1.3141  hLoss: 0.2131  rLoss: 0.2452  oError: 0.4557  conv: 0.4173  avgPre: 0.6113\n","Batch: [0094/0500]  training loss: 0.8611  meta_loss: 1.2526  hLoss: 0.2081  rLoss: 0.2446  oError: 0.4806  conv: 0.4101  avgPre: 0.6086\n","Batch: [0095/0500]  training loss: 0.8606  meta_loss: 1.3030  hLoss: 0.2141  rLoss: 0.2366  oError: 0.4492  conv: 0.4067  avgPre: 0.6272\n","Batch: [0096/0500]  training loss: 0.8570  meta_loss: 1.2811  hLoss: 0.2121  rLoss: 0.2375  oError: 0.4572  conv: 0.4048  avgPre: 0.6222\n","Batch: [0097/0500]  training loss: 0.8525  meta_loss: 1.2191  hLoss: 0.2075  rLoss: 0.2398  oError: 0.4682  conv: 0.4113  avgPre: 0.6153\n","Batch: [0098/0500]  training loss: 0.8544  meta_loss: 1.2738  hLoss: 0.2129  rLoss: 0.2410  oError: 0.4543  conv: 0.4123  avgPre: 0.6206\n","Batch: [0099/0500]  training loss: 0.8578  meta_loss: 1.2890  hLoss: 0.2072  rLoss: 0.2376  oError: 0.4674  conv: 0.4065  avgPre: 0.6172\n","Batch: [0100/0500]  training loss: 0.8547  meta_loss: 1.3112  hLoss: 0.2083  rLoss: 0.2406  oError: 0.4865  conv: 0.4079  avgPre: 0.6082\n","Batch: [0101/0500]  training loss: 0.8531  meta_loss: 1.2443  hLoss: 0.2074  rLoss: 0.2394  oError: 0.4696  conv: 0.4097  avgPre: 0.6170\n","Batch: [0102/0500]  training loss: 0.8503  meta_loss: 1.2620  hLoss: 0.2099  rLoss: 0.2452  oError: 0.4609  conv: 0.4185  avgPre: 0.6094\n","Batch: [0103/0500]  training loss: 0.8568  meta_loss: 1.3035  hLoss: 0.2063  rLoss: 0.2373  oError: 0.4689  conv: 0.4107  avgPre: 0.6168\n","Batch: [0104/0500]  training loss: 0.8480  meta_loss: 1.2761  hLoss: 0.2090  rLoss: 0.2414  oError: 0.4667  conv: 0.4124  avgPre: 0.6118\n","Batch: [0105/0500]  training loss: 0.8478  meta_loss: 1.3520  hLoss: 0.2045  rLoss: 0.2386  oError: 0.4770  conv: 0.4071  avgPre: 0.6133\n","Batch: [0106/0500]  training loss: 0.8514  meta_loss: 1.3210  hLoss: 0.2066  rLoss: 0.2397  oError: 0.4748  conv: 0.4072  avgPre: 0.6145\n","Batch: [0107/0500]  training loss: 0.8507  meta_loss: 1.2830  hLoss: 0.2109  rLoss: 0.2396  oError: 0.4382  conv: 0.4083  avgPre: 0.6274\n","Batch: [0108/0500]  training loss: 0.8570  meta_loss: 1.3582  hLoss: 0.2082  rLoss: 0.2380  oError: 0.4696  conv: 0.4093  avgPre: 0.6158\n","Batch: [0109/0500]  training loss: 0.8533  meta_loss: 1.2763  hLoss: 0.2101  rLoss: 0.2430  oError: 0.4770  conv: 0.4135  avgPre: 0.6108\n","Batch: [0110/0500]  training loss: 0.8557  meta_loss: 1.3172  hLoss: 0.2061  rLoss: 0.2451  oError: 0.4711  conv: 0.4109  avgPre: 0.6187\n","Batch: [0111/0500]  training loss: 0.8535  meta_loss: 1.3054  hLoss: 0.2081  rLoss: 0.2449  oError: 0.4974  conv: 0.4128  avgPre: 0.6029\n","Batch: [0112/0500]  training loss: 0.8523  meta_loss: 1.2691  hLoss: 0.2121  rLoss: 0.2481  oError: 0.4514  conv: 0.4217  avgPre: 0.6082\n","Batch: [0113/0500]  training loss: 0.8573  meta_loss: 1.2661  hLoss: 0.2130  rLoss: 0.2363  oError: 0.4535  conv: 0.4100  avgPre: 0.6189\n","Batch: [0114/0500]  training loss: 0.8541  meta_loss: 1.3589  hLoss: 0.2075  rLoss: 0.2387  oError: 0.4762  conv: 0.4064  avgPre: 0.6139\n","Batch: [0115/0500]  training loss: 0.8527  meta_loss: 1.2758  hLoss: 0.2062  rLoss: 0.2353  oError: 0.4594  conv: 0.4017  avgPre: 0.6204\n","Batch: [0116/0500]  training loss: 0.8568  meta_loss: 1.2852  hLoss: 0.2080  rLoss: 0.2435  oError: 0.4579  conv: 0.4142  avgPre: 0.6124\n","Batch: [0117/0500]  training loss: 0.8530  meta_loss: 1.3011  hLoss: 0.2098  rLoss: 0.2429  oError: 0.4514  conv: 0.4165  avgPre: 0.6159\n","Batch: [0118/0500]  training loss: 0.8526  meta_loss: 1.2507  hLoss: 0.2053  rLoss: 0.2443  oError: 0.4887  conv: 0.4096  avgPre: 0.6081\n","Batch: [0119/0500]  training loss: 0.8503  meta_loss: 1.2658  hLoss: 0.2062  rLoss: 0.2413  oError: 0.4813  conv: 0.4107  avgPre: 0.6089\n","Batch: [0120/0500]  training loss: 0.8466  meta_loss: 1.2618  hLoss: 0.2049  rLoss: 0.2428  oError: 0.4799  conv: 0.4110  avgPre: 0.6076\n","Batch: [0121/0500]  training loss: 0.8459  meta_loss: 1.3114  hLoss: 0.2101  rLoss: 0.2387  oError: 0.4587  conv: 0.4110  avgPre: 0.6155\n","Batch: [0122/0500]  training loss: 0.8486  meta_loss: 1.3136  hLoss: 0.2078  rLoss: 0.2422  oError: 0.4704  conv: 0.4131  avgPre: 0.6128\n","Batch: [0123/0500]  training loss: 0.8485  meta_loss: 1.2953  hLoss: 0.2132  rLoss: 0.2425  oError: 0.4638  conv: 0.4147  avgPre: 0.6119\n","Batch: [0124/0500]  training loss: 0.8600  meta_loss: 1.3328  hLoss: 0.2139  rLoss: 0.2385  oError: 0.4353  conv: 0.4134  avgPre: 0.6265\n","Batch: [0125/0500]  training loss: 0.8568  meta_loss: 1.3125  hLoss: 0.2142  rLoss: 0.2371  oError: 0.4404  conv: 0.4111  avgPre: 0.6237\n","Batch: [0126/0500]  training loss: 0.8490  meta_loss: 1.2487  hLoss: 0.2063  rLoss: 0.2441  oError: 0.4704  conv: 0.4128  avgPre: 0.6119\n","Batch: [0127/0500]  training loss: 0.8482  meta_loss: 1.2788  hLoss: 0.2080  rLoss: 0.2434  oError: 0.4689  conv: 0.4148  avgPre: 0.6075\n","Batch: [0128/0500]  training loss: 0.8509  meta_loss: 1.2885  hLoss: 0.2076  rLoss: 0.2455  oError: 0.4718  conv: 0.4158  avgPre: 0.6066\n","Batch: [0129/0500]  training loss: 0.8542  meta_loss: 1.3573  hLoss: 0.2086  rLoss: 0.2352  oError: 0.4616  conv: 0.4001  avgPre: 0.6222\n","Batch: [0130/0500]  training loss: 0.8521  meta_loss: 1.2455  hLoss: 0.2084  rLoss: 0.2389  oError: 0.4616  conv: 0.4071  avgPre: 0.6165\n","Batch: [0131/0500]  training loss: 0.8605  meta_loss: 1.3963  hLoss: 0.2042  rLoss: 0.2421  oError: 0.4609  conv: 0.4067  avgPre: 0.6157\n","Batch: [0132/0500]  training loss: 0.8546  meta_loss: 1.3278  hLoss: 0.2095  rLoss: 0.2434  oError: 0.4550  conv: 0.4152  avgPre: 0.6160\n","Batch: [0133/0500]  training loss: 0.8510  meta_loss: 1.2566  hLoss: 0.2080  rLoss: 0.2372  oError: 0.4762  conv: 0.4066  avgPre: 0.6154\n","Batch: [0134/0500]  training loss: 0.8495  meta_loss: 1.3057  hLoss: 0.2084  rLoss: 0.2367  oError: 0.4309  conv: 0.4051  avgPre: 0.6275\n","Batch: [0135/0500]  training loss: 0.8470  meta_loss: 1.2912  hLoss: 0.2103  rLoss: 0.2371  oError: 0.4631  conv: 0.4063  avgPre: 0.6171\n","Batch: [0136/0500]  training loss: 0.8436  meta_loss: 1.2867  hLoss: 0.2093  rLoss: 0.2482  oError: 0.4792  conv: 0.4178  avgPre: 0.6026\n","Batch: [0137/0500]  training loss: 0.8410  meta_loss: 1.2939  hLoss: 0.2058  rLoss: 0.2404  oError: 0.4857  conv: 0.4099  avgPre: 0.6093\n","Batch: [0138/0500]  training loss: 0.8366  meta_loss: 1.2779  hLoss: 0.2095  rLoss: 0.2420  oError: 0.4557  conv: 0.4160  avgPre: 0.6167\n","Batch: [0139/0500]  training loss: 0.8410  meta_loss: 1.2594  hLoss: 0.2063  rLoss: 0.2390  oError: 0.4740  conv: 0.4057  avgPre: 0.6136\n","Batch: [0140/0500]  training loss: 0.8403  meta_loss: 1.3058  hLoss: 0.2088  rLoss: 0.2404  oError: 0.4718  conv: 0.4129  avgPre: 0.6107\n","Batch: [0141/0500]  training loss: 0.8392  meta_loss: 1.2591  hLoss: 0.2109  rLoss: 0.2330  oError: 0.4557  conv: 0.4026  avgPre: 0.6226\n","Batch: [0142/0500]  training loss: 0.8414  meta_loss: 1.2657  hLoss: 0.2046  rLoss: 0.2386  oError: 0.4865  conv: 0.4079  avgPre: 0.6098\n","Batch: [0143/0500]  training loss: 0.8467  meta_loss: 1.3195  hLoss: 0.2090  rLoss: 0.2426  oError: 0.4696  conv: 0.4126  avgPre: 0.6119\n","Batch: [0144/0500]  training loss: 0.8491  meta_loss: 1.3727  hLoss: 0.2082  rLoss: 0.2380  oError: 0.4492  conv: 0.4101  avgPre: 0.6217\n","Batch: [0145/0500]  training loss: 0.8444  meta_loss: 1.3034  hLoss: 0.2044  rLoss: 0.2366  oError: 0.4909  conv: 0.4030  avgPre: 0.6110\n","Batch: [0146/0500]  training loss: 0.8432  meta_loss: 1.2907  hLoss: 0.2071  rLoss: 0.2393  oError: 0.4353  conv: 0.4104  avgPre: 0.6205\n","Batch: [0147/0500]  training loss: 0.8437  meta_loss: 1.2783  hLoss: 0.2082  rLoss: 0.2462  oError: 0.4777  conv: 0.4184  avgPre: 0.6014\n","Batch: [0148/0500]  training loss: 0.8383  meta_loss: 1.2410  hLoss: 0.2077  rLoss: 0.2353  oError: 0.4572  conv: 0.4058  avgPre: 0.6190\n","Batch: [0149/0500]  training loss: 0.8333  meta_loss: 1.1747  hLoss: 0.2085  rLoss: 0.2358  oError: 0.4587  conv: 0.4079  avgPre: 0.6199\n","Batch: [0150/0500]  training loss: 0.8319  meta_loss: 1.2534  hLoss: 0.2080  rLoss: 0.2469  oError: 0.4631  conv: 0.4181  avgPre: 0.6061\n","Batch: [0151/0500]  training loss: 0.8357  meta_loss: 1.3069  hLoss: 0.2089  rLoss: 0.2426  oError: 0.4572  conv: 0.4128  avgPre: 0.6168\n","Batch: [0152/0500]  training loss: 0.8387  meta_loss: 1.2840  hLoss: 0.2046  rLoss: 0.2438  oError: 0.4792  conv: 0.4140  avgPre: 0.6063\n","Batch: [0153/0500]  training loss: 0.8376  meta_loss: 1.2631  hLoss: 0.2068  rLoss: 0.2351  oError: 0.4557  conv: 0.4069  avgPre: 0.6224\n","Batch: [0154/0500]  training loss: 0.8402  meta_loss: 1.2829  hLoss: 0.2074  rLoss: 0.2403  oError: 0.4609  conv: 0.4117  avgPre: 0.6138\n","Batch: [0155/0500]  training loss: 0.8399  meta_loss: 1.3027  hLoss: 0.2086  rLoss: 0.2420  oError: 0.4740  conv: 0.4154  avgPre: 0.6101\n","Batch: [0156/0500]  training loss: 0.8422  meta_loss: 1.3622  hLoss: 0.2045  rLoss: 0.2435  oError: 0.4806  conv: 0.4119  avgPre: 0.6064\n","Batch: [0157/0500]  training loss: 0.8433  meta_loss: 1.2958  hLoss: 0.2038  rLoss: 0.2436  oError: 0.4865  conv: 0.4114  avgPre: 0.6082\n","Batch: [0158/0500]  training loss: 0.8488  meta_loss: 1.3888  hLoss: 0.2036  rLoss: 0.2384  oError: 0.4872  conv: 0.4073  avgPre: 0.6092\n","Batch: [0159/0500]  training loss: 0.8492  meta_loss: 1.3671  hLoss: 0.2063  rLoss: 0.2389  oError: 0.4667  conv: 0.4089  avgPre: 0.6130\n","Batch: [0160/0500]  training loss: 0.8407  meta_loss: 1.3205  hLoss: 0.2056  rLoss: 0.2393  oError: 0.4740  conv: 0.4073  avgPre: 0.6110\n","Batch: [0161/0500]  training loss: 0.8415  meta_loss: 1.3264  hLoss: 0.2072  rLoss: 0.2424  oError: 0.4762  conv: 0.4149  avgPre: 0.6034\n","Batch: [0162/0500]  training loss: 0.8400  meta_loss: 1.2222  hLoss: 0.2038  rLoss: 0.2431  oError: 0.4711  conv: 0.4141  avgPre: 0.6069\n","Batch: [0163/0500]  training loss: 0.8425  meta_loss: 1.3588  hLoss: 0.2048  rLoss: 0.2430  oError: 0.4850  conv: 0.4127  avgPre: 0.6070\n","Batch: [0164/0500]  training loss: 0.8391  meta_loss: 1.2866  hLoss: 0.2078  rLoss: 0.2370  oError: 0.4514  conv: 0.4073  avgPre: 0.6199\n","Batch: [0165/0500]  training loss: 0.8354  meta_loss: 1.2641  hLoss: 0.2076  rLoss: 0.2395  oError: 0.4755  conv: 0.4087  avgPre: 0.6097\n","Batch: [0166/0500]  training loss: 0.8353  meta_loss: 1.3147  hLoss: 0.2048  rLoss: 0.2449  oError: 0.4616  conv: 0.4153  avgPre: 0.6128\n","Batch: [0167/0500]  training loss: 0.8412  meta_loss: 1.2884  hLoss: 0.2103  rLoss: 0.2428  oError: 0.4462  conv: 0.4154  avgPre: 0.6150\n","Batch: [0168/0500]  training loss: 0.8447  meta_loss: 1.2913  hLoss: 0.2072  rLoss: 0.2353  oError: 0.4711  conv: 0.4017  avgPre: 0.6162\n","Batch: [0169/0500]  training loss: 0.8428  meta_loss: 1.2831  hLoss: 0.2054  rLoss: 0.2434  oError: 0.4565  conv: 0.4107  avgPre: 0.6140\n","Batch: [0170/0500]  training loss: 0.8383  meta_loss: 1.2828  hLoss: 0.2074  rLoss: 0.2389  oError: 0.4653  conv: 0.4085  avgPre: 0.6181\n","Batch: [0171/0500]  training loss: 0.8394  meta_loss: 1.3075  hLoss: 0.2067  rLoss: 0.2350  oError: 0.4726  conv: 0.4050  avgPre: 0.6164\n","Batch: [0172/0500]  training loss: 0.8368  meta_loss: 1.2716  hLoss: 0.2069  rLoss: 0.2392  oError: 0.4792  conv: 0.4078  avgPre: 0.6089\n","Batch: [0173/0500]  training loss: 0.8372  meta_loss: 1.2540  hLoss: 0.2097  rLoss: 0.2410  oError: 0.4623  conv: 0.4127  avgPre: 0.6127\n","Batch: [0174/0500]  training loss: 0.8358  meta_loss: 1.2548  hLoss: 0.2066  rLoss: 0.2365  oError: 0.4784  conv: 0.4068  avgPre: 0.6132\n","Batch: [0175/0500]  training loss: 0.8372  meta_loss: 1.2704  hLoss: 0.2080  rLoss: 0.2386  oError: 0.4470  conv: 0.4091  avgPre: 0.6185\n","Batch: [0176/0500]  training loss: 0.8392  meta_loss: 1.2586  hLoss: 0.2097  rLoss: 0.2389  oError: 0.4543  conv: 0.4103  avgPre: 0.6166\n","Batch: [0177/0500]  training loss: 0.8423  meta_loss: 1.2764  hLoss: 0.2082  rLoss: 0.2452  oError: 0.4601  conv: 0.4163  avgPre: 0.6122\n","Batch: [0178/0500]  training loss: 0.8404  meta_loss: 1.2733  hLoss: 0.2091  rLoss: 0.2448  oError: 0.4543  conv: 0.4212  avgPre: 0.6147\n","Batch: [0179/0500]  training loss: 0.8412  meta_loss: 1.3088  hLoss: 0.2056  rLoss: 0.2371  oError: 0.4726  conv: 0.4079  avgPre: 0.6144\n","Batch: [0180/0500]  training loss: 0.8358  meta_loss: 1.2595  hLoss: 0.2060  rLoss: 0.2380  oError: 0.4565  conv: 0.4140  avgPre: 0.6180\n","Batch: [0181/0500]  training loss: 0.8347  meta_loss: 1.2324  hLoss: 0.2048  rLoss: 0.2392  oError: 0.4792  conv: 0.4055  avgPre: 0.6124\n","Batch: [0182/0500]  training loss: 0.8369  meta_loss: 1.2612  hLoss: 0.2078  rLoss: 0.2362  oError: 0.4257  conv: 0.4040  avgPre: 0.6323\n","Batch: [0183/0500]  training loss: 0.8377  meta_loss: 1.2409  hLoss: 0.2088  rLoss: 0.2372  oError: 0.4499  conv: 0.4113  avgPre: 0.6210\n","Batch: [0184/0500]  training loss: 0.8392  meta_loss: 1.2526  hLoss: 0.2062  rLoss: 0.2359  oError: 0.4638  conv: 0.4027  avgPre: 0.6181\n","Batch: [0185/0500]  training loss: 0.8422  meta_loss: 1.2264  hLoss: 0.2055  rLoss: 0.2396  oError: 0.4806  conv: 0.4028  avgPre: 0.6115\n","Batch: [0186/0500]  training loss: 0.8449  meta_loss: 1.3061  hLoss: 0.2081  rLoss: 0.2309  oError: 0.4587  conv: 0.3992  avgPre: 0.6237\n","Batch: [0187/0500]  training loss: 0.8423  meta_loss: 1.2828  hLoss: 0.2070  rLoss: 0.2351  oError: 0.4704  conv: 0.4019  avgPre: 0.6166\n","Batch: [0188/0500]  training loss: 0.8377  meta_loss: 1.2613  hLoss: 0.2090  rLoss: 0.2414  oError: 0.4770  conv: 0.4128  avgPre: 0.6082\n","Batch: [0189/0500]  training loss: 0.8402  meta_loss: 1.2924  hLoss: 0.2055  rLoss: 0.2363  oError: 0.4572  conv: 0.4059  avgPre: 0.6216\n","Batch: [0190/0500]  training loss: 0.8362  meta_loss: 1.2587  hLoss: 0.2067  rLoss: 0.2396  oError: 0.4777  conv: 0.4101  avgPre: 0.6115\n","Batch: [0191/0500]  training loss: 0.8380  meta_loss: 1.2712  hLoss: 0.2090  rLoss: 0.2438  oError: 0.4557  conv: 0.4161  avgPre: 0.6132\n","Batch: [0192/0500]  training loss: 0.8365  meta_loss: 1.2719  hLoss: 0.2070  rLoss: 0.2364  oError: 0.4462  conv: 0.4092  avgPre: 0.6245\n","Batch: [0193/0500]  training loss: 0.8297  meta_loss: 1.1936  hLoss: 0.2082  rLoss: 0.2367  oError: 0.4638  conv: 0.4103  avgPre: 0.6150\n","Batch: [0194/0500]  training loss: 0.8263  meta_loss: 1.2133  hLoss: 0.2096  rLoss: 0.2404  oError: 0.4579  conv: 0.4121  avgPre: 0.6169\n","Batch: [0195/0500]  training loss: 0.8291  meta_loss: 1.3410  hLoss: 0.2103  rLoss: 0.2380  oError: 0.4594  conv: 0.4069  avgPre: 0.6169\n","Batch: [0196/0500]  training loss: 0.8312  meta_loss: 1.2502  hLoss: 0.2067  rLoss: 0.2399  oError: 0.4616  conv: 0.4115  avgPre: 0.6157\n","Batch: [0197/0500]  training loss: 0.8291  meta_loss: 1.2295  hLoss: 0.2058  rLoss: 0.2430  oError: 0.4484  conv: 0.4114  avgPre: 0.6185\n","Batch: [0198/0500]  training loss: 0.8348  meta_loss: 1.3328  hLoss: 0.2119  rLoss: 0.2334  oError: 0.4389  conv: 0.4081  avgPre: 0.6265\n","Batch: [0199/0500]  training loss: 0.8351  meta_loss: 1.2507  hLoss: 0.2057  rLoss: 0.2423  oError: 0.4792  conv: 0.4122  avgPre: 0.6100\n","Batch: [0200/0500]  training loss: 0.8359  meta_loss: 1.3378  hLoss: 0.2091  rLoss: 0.2431  oError: 0.4638  conv: 0.4109  avgPre: 0.6155\n","Batch: [0201/0500]  training loss: 0.8343  meta_loss: 1.3034  hLoss: 0.2088  rLoss: 0.2446  oError: 0.4477  conv: 0.4170  avgPre: 0.6141\n","Batch: [0202/0500]  training loss: 0.8390  meta_loss: 1.3065  hLoss: 0.2097  rLoss: 0.2398  oError: 0.4440  conv: 0.4101  avgPre: 0.6227\n","Batch: [0203/0500]  training loss: 0.8327  meta_loss: 1.2818  hLoss: 0.2059  rLoss: 0.2430  oError: 0.4616  conv: 0.4133  avgPre: 0.6146\n","Batch: [0204/0500]  training loss: 0.8329  meta_loss: 1.2469  hLoss: 0.2069  rLoss: 0.2449  oError: 0.4748  conv: 0.4144  avgPre: 0.6052\n","Batch: [0205/0500]  training loss: 0.8382  meta_loss: 1.3062  hLoss: 0.2092  rLoss: 0.2361  oError: 0.4389  conv: 0.4089  avgPre: 0.6232\n","Batch: [0206/0500]  training loss: 0.8367  meta_loss: 1.2833  hLoss: 0.2101  rLoss: 0.2352  oError: 0.4565  conv: 0.4049  avgPre: 0.6197\n","Batch: [0207/0500]  training loss: 0.8408  meta_loss: 1.2717  hLoss: 0.2068  rLoss: 0.2427  oError: 0.4828  conv: 0.4102  avgPre: 0.6086\n","Batch: [0208/0500]  training loss: 0.8402  meta_loss: 1.2309  hLoss: 0.2068  rLoss: 0.2393  oError: 0.4455  conv: 0.4065  avgPre: 0.6204\n","Batch: [0209/0500]  training loss: 0.8391  meta_loss: 1.2387  hLoss: 0.2067  rLoss: 0.2401  oError: 0.4740  conv: 0.4110  avgPre: 0.6124\n","Batch: [0210/0500]  training loss: 0.8386  meta_loss: 1.2918  hLoss: 0.2097  rLoss: 0.2418  oError: 0.4579  conv: 0.4145  avgPre: 0.6140\n","Batch: [0211/0500]  training loss: 0.8355  meta_loss: 1.2859  hLoss: 0.2070  rLoss: 0.2355  oError: 0.4579  conv: 0.4037  avgPre: 0.6203\n","Batch: [0212/0500]  training loss: 0.8312  meta_loss: 1.2687  hLoss: 0.2059  rLoss: 0.2415  oError: 0.4645  conv: 0.4125  avgPre: 0.6129\n","Batch: [0213/0500]  training loss: 0.8319  meta_loss: 1.2089  hLoss: 0.2084  rLoss: 0.2451  oError: 0.4631  conv: 0.4152  avgPre: 0.6111\n","Batch: [0214/0500]  training loss: 0.8315  meta_loss: 1.2039  hLoss: 0.2076  rLoss: 0.2388  oError: 0.4338  conv: 0.4089  avgPre: 0.6210\n","Batch: [0215/0500]  training loss: 0.8338  meta_loss: 1.2747  hLoss: 0.2070  rLoss: 0.2375  oError: 0.4550  conv: 0.4061  avgPre: 0.6216\n","Batch: [0216/0500]  training loss: 0.8390  meta_loss: 1.2630  hLoss: 0.2073  rLoss: 0.2380  oError: 0.4755  conv: 0.4089  avgPre: 0.6120\n","Batch: [0217/0500]  training loss: 0.8363  meta_loss: 1.2654  hLoss: 0.2092  rLoss: 0.2367  oError: 0.4594  conv: 0.4057  avgPre: 0.6182\n","Batch: [0218/0500]  training loss: 0.8346  meta_loss: 1.2761  hLoss: 0.2075  rLoss: 0.2376  oError: 0.4645  conv: 0.4053  avgPre: 0.6171\n","Batch: [0219/0500]  training loss: 0.8320  meta_loss: 1.2608  hLoss: 0.2082  rLoss: 0.2336  oError: 0.4309  conv: 0.4031  avgPre: 0.6308\n","Batch: [0220/0500]  training loss: 0.8346  meta_loss: 1.2452  hLoss: 0.2024  rLoss: 0.2441  oError: 0.4689  conv: 0.4133  avgPre: 0.6104\n","Batch: [0221/0500]  training loss: 0.8431  meta_loss: 1.3935  hLoss: 0.2062  rLoss: 0.2369  oError: 0.4521  conv: 0.4053  avgPre: 0.6227\n","Batch: [0222/0500]  training loss: 0.8325  meta_loss: 1.2854  hLoss: 0.2077  rLoss: 0.2357  oError: 0.4623  conv: 0.4024  avgPre: 0.6215\n","Batch: [0223/0500]  training loss: 0.8295  meta_loss: 1.2096  hLoss: 0.2079  rLoss: 0.2362  oError: 0.4609  conv: 0.4045  avgPre: 0.6208\n","Batch: [0224/0500]  training loss: 0.8323  meta_loss: 1.2674  hLoss: 0.2097  rLoss: 0.2351  oError: 0.4535  conv: 0.4043  avgPre: 0.6224\n","Batch: [0225/0500]  training loss: 0.8315  meta_loss: 1.2166  hLoss: 0.2050  rLoss: 0.2471  oError: 0.4711  conv: 0.4180  avgPre: 0.6057\n","Batch: [0226/0500]  training loss: 0.8339  meta_loss: 1.3148  hLoss: 0.2091  rLoss: 0.2370  oError: 0.4331  conv: 0.4108  avgPre: 0.6244\n","Batch: [0227/0500]  training loss: 0.8341  meta_loss: 1.3058  hLoss: 0.2072  rLoss: 0.2392  oError: 0.4550  conv: 0.4102  avgPre: 0.6211\n","Batch: [0228/0500]  training loss: 0.8401  meta_loss: 1.2736  hLoss: 0.2042  rLoss: 0.2436  oError: 0.4989  conv: 0.4128  avgPre: 0.6009\n","Batch: [0229/0500]  training loss: 0.8391  meta_loss: 1.2272  hLoss: 0.2057  rLoss: 0.2460  oError: 0.4799  conv: 0.4160  avgPre: 0.6016\n","Batch: [0230/0500]  training loss: 0.8306  meta_loss: 1.2753  hLoss: 0.2097  rLoss: 0.2399  oError: 0.4484  conv: 0.4135  avgPre: 0.6186\n","Batch: [0231/0500]  training loss: 0.8309  meta_loss: 1.2029  hLoss: 0.2047  rLoss: 0.2354  oError: 0.4784  conv: 0.4034  avgPre: 0.6145\n","Batch: [0232/0500]  training loss: 0.8301  meta_loss: 1.2253  hLoss: 0.2043  rLoss: 0.2392  oError: 0.4916  conv: 0.4075  avgPre: 0.6077\n","Batch: [0233/0500]  training loss: 0.8297  meta_loss: 1.2790  hLoss: 0.2061  rLoss: 0.2376  oError: 0.4674  conv: 0.4058  avgPre: 0.6172\n","Batch: [0234/0500]  training loss: 0.8314  meta_loss: 1.2678  hLoss: 0.2079  rLoss: 0.2461  oError: 0.4594  conv: 0.4168  avgPre: 0.6097\n","Batch: [0235/0500]  training loss: 0.8317  meta_loss: 1.2031  hLoss: 0.2082  rLoss: 0.2417  oError: 0.4557  conv: 0.4124  avgPre: 0.6147\n","Batch: [0236/0500]  training loss: 0.8375  meta_loss: 1.2637  hLoss: 0.2018  rLoss: 0.2393  oError: 0.4543  conv: 0.4039  avgPre: 0.6174\n","Batch: [0237/0500]  training loss: 0.8360  meta_loss: 1.2645  hLoss: 0.2062  rLoss: 0.2418  oError: 0.4674  conv: 0.4146  avgPre: 0.6105\n","Batch: [0238/0500]  training loss: 0.8356  meta_loss: 1.3000  hLoss: 0.2077  rLoss: 0.2414  oError: 0.4601  conv: 0.4154  avgPre: 0.6143\n","Batch: [0239/0500]  training loss: 0.8354  meta_loss: 1.3071  hLoss: 0.2044  rLoss: 0.2378  oError: 0.4777  conv: 0.4071  avgPre: 0.6137\n","Batch: [0240/0500]  training loss: 0.8352  meta_loss: 1.2612  hLoss: 0.2062  rLoss: 0.2381  oError: 0.4667  conv: 0.4047  avgPre: 0.6159\n","Batch: [0241/0500]  training loss: 0.8305  meta_loss: 1.2771  hLoss: 0.2082  rLoss: 0.2366  oError: 0.4484  conv: 0.4081  avgPre: 0.6241\n","Batch: [0242/0500]  training loss: 0.8324  meta_loss: 1.2911  hLoss: 0.2063  rLoss: 0.2440  oError: 0.4499  conv: 0.4163  avgPre: 0.6123\n","Batch: [0243/0500]  training loss: 0.8343  meta_loss: 1.2802  hLoss: 0.2076  rLoss: 0.2424  oError: 0.4682  conv: 0.4102  avgPre: 0.6129\n","Batch: [0244/0500]  training loss: 0.8338  meta_loss: 1.2782  hLoss: 0.2072  rLoss: 0.2398  oError: 0.4674  conv: 0.4113  avgPre: 0.6145\n","Batch: [0245/0500]  training loss: 0.8318  meta_loss: 1.2548  hLoss: 0.2092  rLoss: 0.2395  oError: 0.4440  conv: 0.4116  avgPre: 0.6194\n","Batch: [0246/0500]  training loss: 0.8317  meta_loss: 1.2717  hLoss: 0.2065  rLoss: 0.2395  oError: 0.4426  conv: 0.4119  avgPre: 0.6192\n","Batch: [0247/0500]  training loss: 0.8328  meta_loss: 1.2803  hLoss: 0.2106  rLoss: 0.2404  oError: 0.4214  conv: 0.4159  avgPre: 0.6243\n","Batch: [0248/0500]  training loss: 0.8317  meta_loss: 1.3233  hLoss: 0.2082  rLoss: 0.2399  oError: 0.4557  conv: 0.4102  avgPre: 0.6183\n","Batch: [0249/0500]  training loss: 0.8270  meta_loss: 1.1948  hLoss: 0.2072  rLoss: 0.2398  oError: 0.4587  conv: 0.4101  avgPre: 0.6174\n","Batch: [0250/0500]  training loss: 0.8214  meta_loss: 1.2395  hLoss: 0.2075  rLoss: 0.2417  oError: 0.4272  conv: 0.4149  avgPre: 0.6237\n","Batch: [0251/0500]  training loss: 0.8241  meta_loss: 1.2734  hLoss: 0.2097  rLoss: 0.2389  oError: 0.4653  conv: 0.4110  avgPre: 0.6170\n","Batch: [0252/0500]  training loss: 0.8272  meta_loss: 1.2579  hLoss: 0.2092  rLoss: 0.2377  oError: 0.4448  conv: 0.4105  avgPre: 0.6207\n","Batch: [0253/0500]  training loss: 0.8326  meta_loss: 1.3132  hLoss: 0.2078  rLoss: 0.2416  oError: 0.4718  conv: 0.4135  avgPre: 0.6117\n","Batch: [0254/0500]  training loss: 0.8355  meta_loss: 1.2821  hLoss: 0.2050  rLoss: 0.2405  oError: 0.4857  conv: 0.4102  avgPre: 0.6080\n","Batch: [0255/0500]  training loss: 0.8343  meta_loss: 1.2525  hLoss: 0.2080  rLoss: 0.2354  oError: 0.4579  conv: 0.4060  avgPre: 0.6219\n","Batch: [0256/0500]  training loss: 0.8353  meta_loss: 1.2667  hLoss: 0.2062  rLoss: 0.2377  oError: 0.5040  conv: 0.4044  avgPre: 0.6043\n","Batch: [0257/0500]  training loss: 0.8448  meta_loss: 1.3355  hLoss: 0.2064  rLoss: 0.2397  oError: 0.4872  conv: 0.4127  avgPre: 0.6049\n","Batch: [0258/0500]  training loss: 0.8340  meta_loss: 1.2588  hLoss: 0.2079  rLoss: 0.2371  oError: 0.4579  conv: 0.4072  avgPre: 0.6187\n","Batch: [0259/0500]  training loss: 0.8293  meta_loss: 1.2621  hLoss: 0.2076  rLoss: 0.2400  oError: 0.4382  conv: 0.4093  avgPre: 0.6221\n","Batch: [0260/0500]  training loss: 0.8297  meta_loss: 1.2510  hLoss: 0.2088  rLoss: 0.2377  oError: 0.4506  conv: 0.4080  avgPre: 0.6239\n","Batch: [0261/0500]  training loss: 0.8310  meta_loss: 1.2274  hLoss: 0.2085  rLoss: 0.2375  oError: 0.4806  conv: 0.4050  avgPre: 0.6130\n","Batch: [0262/0500]  training loss: 0.8342  meta_loss: 1.2880  hLoss: 0.2058  rLoss: 0.2365  oError: 0.4645  conv: 0.4084  avgPre: 0.6181\n","Batch: [0263/0500]  training loss: 0.8316  meta_loss: 1.2388  hLoss: 0.2047  rLoss: 0.2382  oError: 0.4733  conv: 0.4055  avgPre: 0.6157\n","Batch: [0264/0500]  training loss: 0.8355  meta_loss: 1.3060  hLoss: 0.2033  rLoss: 0.2389  oError: 0.4645  conv: 0.4089  avgPre: 0.6169\n","Batch: [0265/0500]  training loss: 0.8333  meta_loss: 1.3048  hLoss: 0.2088  rLoss: 0.2384  oError: 0.4294  conv: 0.4109  avgPre: 0.6272\n","Batch: [0266/0500]  training loss: 0.8337  meta_loss: 1.2413  hLoss: 0.2065  rLoss: 0.2381  oError: 0.4674  conv: 0.4082  avgPre: 0.6167\n","Batch: [0267/0500]  training loss: 0.8361  meta_loss: 1.2635  hLoss: 0.2085  rLoss: 0.2416  oError: 0.4623  conv: 0.4134  avgPre: 0.6124\n","Batch: [0268/0500]  training loss: 0.8350  meta_loss: 1.3234  hLoss: 0.2043  rLoss: 0.2374  oError: 0.4704  conv: 0.4057  avgPre: 0.6171\n","Batch: [0269/0500]  training loss: 0.8319  meta_loss: 1.2360  hLoss: 0.2080  rLoss: 0.2399  oError: 0.4572  conv: 0.4130  avgPre: 0.6156\n","Batch: [0270/0500]  training loss: 0.8316  meta_loss: 1.2831  hLoss: 0.2084  rLoss: 0.2382  oError: 0.4199  conv: 0.4107  avgPre: 0.6277\n","Batch: [0271/0500]  training loss: 0.8316  meta_loss: 1.2308  hLoss: 0.2074  rLoss: 0.2381  oError: 0.4535  conv: 0.4063  avgPre: 0.6234\n","Batch: [0272/0500]  training loss: 0.8304  meta_loss: 1.3043  hLoss: 0.2105  rLoss: 0.2364  oError: 0.4345  conv: 0.4042  avgPre: 0.6277\n","Batch: [0273/0500]  training loss: 0.8349  meta_loss: 1.2436  hLoss: 0.2061  rLoss: 0.2367  oError: 0.4674  conv: 0.4027  avgPre: 0.6167\n","Batch: [0274/0500]  training loss: 0.8309  meta_loss: 1.2585  hLoss: 0.2072  rLoss: 0.2387  oError: 0.4535  conv: 0.4085  avgPre: 0.6213\n","Batch: [0275/0500]  training loss: 0.8315  meta_loss: 1.2925  hLoss: 0.2125  rLoss: 0.2338  oError: 0.4162  conv: 0.4058  avgPre: 0.6354\n","Batch: [0276/0500]  training loss: 0.8361  meta_loss: 1.2785  hLoss: 0.2060  rLoss: 0.2347  oError: 0.4865  conv: 0.3986  avgPre: 0.6129\n","Batch: [0277/0500]  training loss: 0.8362  meta_loss: 1.2810  hLoss: 0.2101  rLoss: 0.2353  oError: 0.4323  conv: 0.4058  avgPre: 0.6273\n","Batch: [0278/0500]  training loss: 0.8317  meta_loss: 1.2780  hLoss: 0.2099  rLoss: 0.2365  oError: 0.4616  conv: 0.4090  avgPre: 0.6170\n","Batch: [0279/0500]  training loss: 0.8298  meta_loss: 1.1769  hLoss: 0.2083  rLoss: 0.2351  oError: 0.4514  conv: 0.4069  avgPre: 0.6219\n","Batch: [0280/0500]  training loss: 0.8304  meta_loss: 1.3126  hLoss: 0.2070  rLoss: 0.2372  oError: 0.4470  conv: 0.4058  avgPre: 0.6221\n","Batch: [0281/0500]  training loss: 0.8254  meta_loss: 1.1694  hLoss: 0.2054  rLoss: 0.2388  oError: 0.4689  conv: 0.4066  avgPre: 0.6172\n","Batch: [0282/0500]  training loss: 0.8261  meta_loss: 1.2471  hLoss: 0.2090  rLoss: 0.2392  oError: 0.4616  conv: 0.4119  avgPre: 0.6165\n","Batch: [0283/0500]  training loss: 0.8298  meta_loss: 1.3274  hLoss: 0.2107  rLoss: 0.2369  oError: 0.4557  conv: 0.4065  avgPre: 0.6220\n","Batch: [0284/0500]  training loss: 0.8356  meta_loss: 1.2292  hLoss: 0.2112  rLoss: 0.2375  oError: 0.4192  conv: 0.4103  avgPre: 0.6330\n","Batch: [0285/0500]  training loss: 0.8407  meta_loss: 1.2723  hLoss: 0.2044  rLoss: 0.2424  oError: 0.4857  conv: 0.4119  avgPre: 0.6060\n","Batch: [0286/0500]  training loss: 0.8408  meta_loss: 1.3038  hLoss: 0.2088  rLoss: 0.2399  oError: 0.4616  conv: 0.4147  avgPre: 0.6106\n","Batch: [0287/0500]  training loss: 0.8352  meta_loss: 1.2754  hLoss: 0.2074  rLoss: 0.2347  oError: 0.4528  conv: 0.4045  avgPre: 0.6249\n","Batch: [0288/0500]  training loss: 0.8352  meta_loss: 1.2293  hLoss: 0.2053  rLoss: 0.2388  oError: 0.4382  conv: 0.4081  avgPre: 0.6223\n","Batch: [0289/0500]  training loss: 0.8351  meta_loss: 1.2203  hLoss: 0.2102  rLoss: 0.2309  oError: 0.4426  conv: 0.4003  avgPre: 0.6287\n","Batch: [0290/0500]  training loss: 0.8329  meta_loss: 1.2561  hLoss: 0.2033  rLoss: 0.2426  oError: 0.4923  conv: 0.4108  avgPre: 0.6033\n","Batch: [0291/0500]  training loss: 0.8336  meta_loss: 1.2376  hLoss: 0.2057  rLoss: 0.2424  oError: 0.4638  conv: 0.4134  avgPre: 0.6125\n","Batch: [0292/0500]  training loss: 0.8310  meta_loss: 1.2427  hLoss: 0.2096  rLoss: 0.2363  oError: 0.4594  conv: 0.4081  avgPre: 0.6205\n","Batch: [0293/0500]  training loss: 0.8295  meta_loss: 1.3017  hLoss: 0.2055  rLoss: 0.2353  oError: 0.4711  conv: 0.4031  avgPre: 0.6177\n","Batch: [0294/0500]  training loss: 0.8287  meta_loss: 1.2660  hLoss: 0.2083  rLoss: 0.2367  oError: 0.4404  conv: 0.4053  avgPre: 0.6269\n","Batch: [0295/0500]  training loss: 0.8341  meta_loss: 1.3206  hLoss: 0.2039  rLoss: 0.2345  oError: 0.4689  conv: 0.4010  avgPre: 0.6199\n","Batch: [0296/0500]  training loss: 0.8330  meta_loss: 1.2528  hLoss: 0.2076  rLoss: 0.2336  oError: 0.4389  conv: 0.4042  avgPre: 0.6280\n","Batch: [0297/0500]  training loss: 0.8368  meta_loss: 1.3207  hLoss: 0.2046  rLoss: 0.2388  oError: 0.4777  conv: 0.4091  avgPre: 0.6087\n","Batch: [0298/0500]  training loss: 0.8348  meta_loss: 1.2572  hLoss: 0.2054  rLoss: 0.2407  oError: 0.4601  conv: 0.4127  avgPre: 0.6139\n","Batch: [0299/0500]  training loss: 0.8353  meta_loss: 1.2681  hLoss: 0.2091  rLoss: 0.2322  oError: 0.4543  conv: 0.4019  avgPre: 0.6261\n","Batch: [0300/0500]  training loss: 0.8374  meta_loss: 1.2614  hLoss: 0.2067  rLoss: 0.2370  oError: 0.4579  conv: 0.4112  avgPre: 0.6180\n","Batch: [0301/0500]  training loss: 0.8392  meta_loss: 1.3085  hLoss: 0.2049  rLoss: 0.2350  oError: 0.4470  conv: 0.4021  avgPre: 0.6287\n","Batch: [0302/0500]  training loss: 0.8354  meta_loss: 1.2458  hLoss: 0.2082  rLoss: 0.2350  oError: 0.4477  conv: 0.4048  avgPre: 0.6226\n","Batch: [0303/0500]  training loss: 0.8321  meta_loss: 1.2360  hLoss: 0.2046  rLoss: 0.2438  oError: 0.4638  conv: 0.4165  avgPre: 0.6106\n","Batch: [0304/0500]  training loss: 0.8295  meta_loss: 1.2329  hLoss: 0.2049  rLoss: 0.2436  oError: 0.4718  conv: 0.4150  avgPre: 0.6064\n","Batch: [0305/0500]  training loss: 0.8320  meta_loss: 1.2480  hLoss: 0.2039  rLoss: 0.2420  oError: 0.4835  conv: 0.4096  avgPre: 0.6075\n","Batch: [0306/0500]  training loss: 0.8333  meta_loss: 1.2393  hLoss: 0.2089  rLoss: 0.2377  oError: 0.4389  conv: 0.4095  avgPre: 0.6242\n","Batch: [0307/0500]  training loss: 0.8309  meta_loss: 1.2034  hLoss: 0.2070  rLoss: 0.2402  oError: 0.4594  conv: 0.4119  avgPre: 0.6149\n","Batch: [0308/0500]  training loss: 0.8297  meta_loss: 1.2201  hLoss: 0.2047  rLoss: 0.2398  oError: 0.4748  conv: 0.4077  avgPre: 0.6117\n","Batch: [0309/0500]  training loss: 0.8284  meta_loss: 1.2433  hLoss: 0.2060  rLoss: 0.2388  oError: 0.4696  conv: 0.4119  avgPre: 0.6127\n","Batch: [0310/0500]  training loss: 0.8300  meta_loss: 1.3027  hLoss: 0.2115  rLoss: 0.2371  oError: 0.4272  conv: 0.4106  avgPre: 0.6287\n","Batch: [0311/0500]  training loss: 0.8280  meta_loss: 1.2709  hLoss: 0.2069  rLoss: 0.2412  oError: 0.4550  conv: 0.4134  avgPre: 0.6144\n","Batch: [0312/0500]  training loss: 0.8274  meta_loss: 1.3295  hLoss: 0.2080  rLoss: 0.2347  oError: 0.4645  conv: 0.4051  avgPre: 0.6175\n","Batch: [0313/0500]  training loss: 0.8275  meta_loss: 1.2198  hLoss: 0.2054  rLoss: 0.2382  oError: 0.4865  conv: 0.4028  avgPre: 0.6121\n","Batch: [0314/0500]  training loss: 0.8320  meta_loss: 1.2819  hLoss: 0.2065  rLoss: 0.2403  oError: 0.4770  conv: 0.4112  avgPre: 0.6069\n","Batch: [0315/0500]  training loss: 0.8280  meta_loss: 1.2845  hLoss: 0.2099  rLoss: 0.2330  oError: 0.4528  conv: 0.4024  avgPre: 0.6228\n","Batch: [0316/0500]  training loss: 0.8292  meta_loss: 1.2292  hLoss: 0.2094  rLoss: 0.2343  oError: 0.4557  conv: 0.4048  avgPre: 0.6225\n","Batch: [0317/0500]  training loss: 0.8299  meta_loss: 1.2771  hLoss: 0.2057  rLoss: 0.2355  oError: 0.4689  conv: 0.4067  avgPre: 0.6158\n","Batch: [0318/0500]  training loss: 0.8267  meta_loss: 1.2388  hLoss: 0.2079  rLoss: 0.2376  oError: 0.4565  conv: 0.4080  avgPre: 0.6214\n","Batch: [0319/0500]  training loss: 0.8275  meta_loss: 1.2706  hLoss: 0.2068  rLoss: 0.2379  oError: 0.4872  conv: 0.4083  avgPre: 0.6083\n","Batch: [0320/0500]  training loss: 0.8307  meta_loss: 1.2536  hLoss: 0.2078  rLoss: 0.2422  oError: 0.4653  conv: 0.4151  avgPre: 0.6121\n","Batch: [0321/0500]  training loss: 0.8316  meta_loss: 1.2768  hLoss: 0.2092  rLoss: 0.2366  oError: 0.4535  conv: 0.4077  avgPre: 0.6204\n","Batch: [0322/0500]  training loss: 0.8293  meta_loss: 1.2523  hLoss: 0.2069  rLoss: 0.2377  oError: 0.4623  conv: 0.4075  avgPre: 0.6197\n","Batch: [0323/0500]  training loss: 0.8282  meta_loss: 1.2147  hLoss: 0.2056  rLoss: 0.2397  oError: 0.4653  conv: 0.4112  avgPre: 0.6143\n","Batch: [0324/0500]  training loss: 0.8257  meta_loss: 1.2140  hLoss: 0.2048  rLoss: 0.2432  oError: 0.4857  conv: 0.4152  avgPre: 0.6035\n","Batch: [0325/0500]  training loss: 0.8301  meta_loss: 1.2933  hLoss: 0.2094  rLoss: 0.2328  oError: 0.4704  conv: 0.3969  avgPre: 0.6219\n","Batch: [0326/0500]  training loss: 0.8298  meta_loss: 1.2790  hLoss: 0.2074  rLoss: 0.2435  oError: 0.4799  conv: 0.4149  avgPre: 0.6016\n","Batch: [0327/0500]  training loss: 0.8317  meta_loss: 1.2386  hLoss: 0.2075  rLoss: 0.2398  oError: 0.4609  conv: 0.4133  avgPre: 0.6122\n","Batch: [0328/0500]  training loss: 0.8280  meta_loss: 1.2863  hLoss: 0.2050  rLoss: 0.2386  oError: 0.4689  conv: 0.4115  avgPre: 0.6129\n","Batch: [0329/0500]  training loss: 0.8305  meta_loss: 1.3113  hLoss: 0.2060  rLoss: 0.2432  oError: 0.4667  conv: 0.4137  avgPre: 0.6108\n","Batch: [0330/0500]  training loss: 0.8321  meta_loss: 1.2531  hLoss: 0.2056  rLoss: 0.2391  oError: 0.4287  conv: 0.4115  avgPre: 0.6257\n","Batch: [0331/0500]  training loss: 0.8294  meta_loss: 1.2406  hLoss: 0.2093  rLoss: 0.2332  oError: 0.4579  conv: 0.4044  avgPre: 0.6234\n","Batch: [0332/0500]  training loss: 0.8300  meta_loss: 1.2561  hLoss: 0.2085  rLoss: 0.2374  oError: 0.4594  conv: 0.4104  avgPre: 0.6184\n","Batch: [0333/0500]  training loss: 0.8312  meta_loss: 1.2461  hLoss: 0.2073  rLoss: 0.2355  oError: 0.4294  conv: 0.4067  avgPre: 0.6303\n","Batch: [0334/0500]  training loss: 0.8342  meta_loss: 1.2253  hLoss: 0.2045  rLoss: 0.2385  oError: 0.4865  conv: 0.4077  avgPre: 0.6096\n","Batch: [0335/0500]  training loss: 0.8350  meta_loss: 1.2559  hLoss: 0.2086  rLoss: 0.2438  oError: 0.4631  conv: 0.4162  avgPre: 0.6111\n","Batch: [0336/0500]  training loss: 0.8334  meta_loss: 1.2829  hLoss: 0.2064  rLoss: 0.2343  oError: 0.4638  conv: 0.4035  avgPre: 0.6219\n","Batch: [0337/0500]  training loss: 0.8325  meta_loss: 1.1956  hLoss: 0.2068  rLoss: 0.2368  oError: 0.4704  conv: 0.4075  avgPre: 0.6170\n","Batch: [0338/0500]  training loss: 0.8333  meta_loss: 1.2603  hLoss: 0.2109  rLoss: 0.2343  oError: 0.4535  conv: 0.4049  avgPre: 0.6225\n","Batch: [0339/0500]  training loss: 0.8346  meta_loss: 1.2660  hLoss: 0.2050  rLoss: 0.2362  oError: 0.4982  conv: 0.4043  avgPre: 0.6085\n","Batch: [0340/0500]  training loss: 0.8313  meta_loss: 1.2794  hLoss: 0.2099  rLoss: 0.2350  oError: 0.4535  conv: 0.4059  avgPre: 0.6227\n","Batch: [0341/0500]  training loss: 0.8346  meta_loss: 1.2533  hLoss: 0.2073  rLoss: 0.2340  oError: 0.4631  conv: 0.4055  avgPre: 0.6209\n","Batch: [0342/0500]  training loss: 0.8337  meta_loss: 1.2986  hLoss: 0.2052  rLoss: 0.2445  oError: 0.5128  conv: 0.4080  avgPre: 0.5981\n","Batch: [0343/0500]  training loss: 0.8366  meta_loss: 1.3369  hLoss: 0.2075  rLoss: 0.2335  oError: 0.4748  conv: 0.4031  avgPre: 0.6168\n","Batch: [0344/0500]  training loss: 0.8329  meta_loss: 1.2662  hLoss: 0.2086  rLoss: 0.2331  oError: 0.4221  conv: 0.4061  avgPre: 0.6308\n","Batch: [0345/0500]  training loss: 0.8274  meta_loss: 1.1859  hLoss: 0.2082  rLoss: 0.2343  oError: 0.4514  conv: 0.4093  avgPre: 0.6229\n","Batch: [0346/0500]  training loss: 0.8274  meta_loss: 1.2439  hLoss: 0.2086  rLoss: 0.2423  oError: 0.4587  conv: 0.4148  avgPre: 0.6153\n","Batch: [0347/0500]  training loss: 0.8291  meta_loss: 1.2500  hLoss: 0.2040  rLoss: 0.2347  oError: 0.4682  conv: 0.4073  avgPre: 0.6176\n","Batch: [0348/0500]  training loss: 0.8277  meta_loss: 1.2727  hLoss: 0.2054  rLoss: 0.2394  oError: 0.4835  conv: 0.4086  avgPre: 0.6091\n","Batch: [0349/0500]  training loss: 0.8308  meta_loss: 1.2557  hLoss: 0.2109  rLoss: 0.2306  oError: 0.4455  conv: 0.3984  avgPre: 0.6315\n","Batch: [0350/0500]  training loss: 0.8343  meta_loss: 1.2502  hLoss: 0.2044  rLoss: 0.2398  oError: 0.4426  conv: 0.4128  avgPre: 0.6195\n","Batch: [0351/0500]  training loss: 0.8325  meta_loss: 1.2710  hLoss: 0.2092  rLoss: 0.2324  oError: 0.4572  conv: 0.4001  avgPre: 0.6240\n","Batch: [0352/0500]  training loss: 0.8329  meta_loss: 1.2916  hLoss: 0.2123  rLoss: 0.2363  oError: 0.4426  conv: 0.4130  avgPre: 0.6217\n","Batch: [0353/0500]  training loss: 0.8320  meta_loss: 1.2031  hLoss: 0.2097  rLoss: 0.2367  oError: 0.4528  conv: 0.4098  avgPre: 0.6206\n","Batch: [0354/0500]  training loss: 0.8312  meta_loss: 1.2406  hLoss: 0.2058  rLoss: 0.2393  oError: 0.4309  conv: 0.4117  avgPre: 0.6263\n","Batch: [0355/0500]  training loss: 0.8327  meta_loss: 1.2709  hLoss: 0.2092  rLoss: 0.2352  oError: 0.4462  conv: 0.4068  avgPre: 0.6248\n","Batch: [0356/0500]  training loss: 0.8420  meta_loss: 1.3097  hLoss: 0.2044  rLoss: 0.2406  oError: 0.4696  conv: 0.4122  avgPre: 0.6127\n","Batch: [0357/0500]  training loss: 0.8424  meta_loss: 1.3339  hLoss: 0.2056  rLoss: 0.2400  oError: 0.4492  conv: 0.4116  avgPre: 0.6201\n","Batch: [0358/0500]  training loss: 0.8382  meta_loss: 1.3082  hLoss: 0.2046  rLoss: 0.2423  oError: 0.4770  conv: 0.4122  avgPre: 0.6082\n","Batch: [0359/0500]  training loss: 0.8331  meta_loss: 1.2289  hLoss: 0.2078  rLoss: 0.2346  oError: 0.4375  conv: 0.4087  avgPre: 0.6245\n","Batch: [0360/0500]  training loss: 0.8349  meta_loss: 1.2617  hLoss: 0.2086  rLoss: 0.2375  oError: 0.4221  conv: 0.4089  avgPre: 0.6300\n","Batch: [0361/0500]  training loss: 0.8322  meta_loss: 1.2464  hLoss: 0.2054  rLoss: 0.2386  oError: 0.4762  conv: 0.4084  avgPre: 0.6112\n","Batch: [0362/0500]  training loss: 0.8349  meta_loss: 1.2771  hLoss: 0.2065  rLoss: 0.2396  oError: 0.4550  conv: 0.4105  avgPre: 0.6172\n","Batch: [0363/0500]  training loss: 0.8332  meta_loss: 1.2719  hLoss: 0.2030  rLoss: 0.2417  oError: 0.4850  conv: 0.4073  avgPre: 0.6090\n","Batch: [0364/0500]  training loss: 0.8329  meta_loss: 1.2748  hLoss: 0.2086  rLoss: 0.2387  oError: 0.4579  conv: 0.4109  avgPre: 0.6177\n","Batch: [0365/0500]  training loss: 0.8335  meta_loss: 1.2275  hLoss: 0.2095  rLoss: 0.2434  oError: 0.4579  conv: 0.4152  avgPre: 0.6115\n","Batch: [0366/0500]  training loss: 0.8384  meta_loss: 1.3198  hLoss: 0.2099  rLoss: 0.2332  oError: 0.4587  conv: 0.4003  avgPre: 0.6229\n","Batch: [0367/0500]  training loss: 0.8360  meta_loss: 1.2119  hLoss: 0.2050  rLoss: 0.2421  oError: 0.5033  conv: 0.4109  avgPre: 0.6003\n","Batch: [0368/0500]  training loss: 0.8393  meta_loss: 1.2598  hLoss: 0.2078  rLoss: 0.2414  oError: 0.4543  conv: 0.4167  avgPre: 0.6155\n","Batch: [0369/0500]  training loss: 0.8380  meta_loss: 1.2853  hLoss: 0.2101  rLoss: 0.2418  oError: 0.4345  conv: 0.4194  avgPre: 0.6202\n","Batch: [0370/0500]  training loss: 0.8412  meta_loss: 1.3474  hLoss: 0.2098  rLoss: 0.2296  oError: 0.4250  conv: 0.3942  avgPre: 0.6366\n","Batch: [0371/0500]  training loss: 0.8364  meta_loss: 1.2770  hLoss: 0.2035  rLoss: 0.2402  oError: 0.4543  conv: 0.4107  avgPre: 0.6181\n","Batch: [0372/0500]  training loss: 0.8358  meta_loss: 1.3082  hLoss: 0.2042  rLoss: 0.2353  oError: 0.4996  conv: 0.4029  avgPre: 0.6083\n","Batch: [0373/0500]  training loss: 0.8295  meta_loss: 1.2220  hLoss: 0.2089  rLoss: 0.2365  oError: 0.4462  conv: 0.4082  avgPre: 0.6248\n","Batch: [0374/0500]  training loss: 0.8327  meta_loss: 1.2556  hLoss: 0.2072  rLoss: 0.2395  oError: 0.4557  conv: 0.4123  avgPre: 0.6161\n","Batch: [0375/0500]  training loss: 0.8345  meta_loss: 1.2952  hLoss: 0.2088  rLoss: 0.2348  oError: 0.4543  conv: 0.4065  avgPre: 0.6199\n","Batch: [0376/0500]  training loss: 0.8358  meta_loss: 1.3090  hLoss: 0.2105  rLoss: 0.2379  oError: 0.4462  conv: 0.4110  avgPre: 0.6230\n","Batch: [0377/0500]  training loss: 0.8376  meta_loss: 1.2555  hLoss: 0.2053  rLoss: 0.2383  oError: 0.4696  conv: 0.4097  avgPre: 0.6142\n","Batch: [0378/0500]  training loss: 0.8365  meta_loss: 1.3019  hLoss: 0.2072  rLoss: 0.2370  oError: 0.4572  conv: 0.4068  avgPre: 0.6179\n","Batch: [0379/0500]  training loss: 0.8436  meta_loss: 1.3082  hLoss: 0.2077  rLoss: 0.2397  oError: 0.4477  conv: 0.4151  avgPre: 0.6187\n","Batch: [0380/0500]  training loss: 0.8471  meta_loss: 1.3826  hLoss: 0.2039  rLoss: 0.2400  oError: 0.4784  conv: 0.4035  avgPre: 0.6140\n","Batch: [0381/0500]  training loss: 0.8407  meta_loss: 1.3039  hLoss: 0.2064  rLoss: 0.2384  oError: 0.4821  conv: 0.4085  avgPre: 0.6074\n","Batch: [0382/0500]  training loss: 0.8375  meta_loss: 1.2652  hLoss: 0.2089  rLoss: 0.2346  oError: 0.4279  conv: 0.4067  avgPre: 0.6276\n","Batch: [0383/0500]  training loss: 0.8343  meta_loss: 1.2460  hLoss: 0.2040  rLoss: 0.2406  oError: 0.4813  conv: 0.4097  avgPre: 0.6102\n","Batch: [0384/0500]  training loss: 0.8311  meta_loss: 1.2678  hLoss: 0.2063  rLoss: 0.2359  oError: 0.4609  conv: 0.4045  avgPre: 0.6199\n","Batch: [0385/0500]  training loss: 0.8334  meta_loss: 1.2766  hLoss: 0.2094  rLoss: 0.2331  oError: 0.4579  conv: 0.4041  avgPre: 0.6208\n","Batch: [0386/0500]  training loss: 0.8319  meta_loss: 1.1936  hLoss: 0.2068  rLoss: 0.2377  oError: 0.4579  conv: 0.4047  avgPre: 0.6209\n","Batch: [0387/0500]  training loss: 0.8366  meta_loss: 1.3312  hLoss: 0.2061  rLoss: 0.2409  oError: 0.4828  conv: 0.4097  avgPre: 0.6072\n","Batch: [0388/0500]  training loss: 0.8345  meta_loss: 1.2484  hLoss: 0.2090  rLoss: 0.2381  oError: 0.4426  conv: 0.4130  avgPre: 0.6229\n","Batch: [0389/0500]  training loss: 0.8355  meta_loss: 1.2956  hLoss: 0.2067  rLoss: 0.2383  oError: 0.4535  conv: 0.4104  avgPre: 0.6173\n","Batch: [0390/0500]  training loss: 0.8325  meta_loss: 1.2709  hLoss: 0.2074  rLoss: 0.2394  oError: 0.4587  conv: 0.4082  avgPre: 0.6177\n","Batch: [0391/0500]  training loss: 0.8307  meta_loss: 1.1948  hLoss: 0.2076  rLoss: 0.2372  oError: 0.4594  conv: 0.4065  avgPre: 0.6191\n","Batch: [0392/0500]  training loss: 0.8298  meta_loss: 1.2500  hLoss: 0.2094  rLoss: 0.2394  oError: 0.4506  conv: 0.4132  avgPre: 0.6185\n","Batch: [0393/0500]  training loss: 0.8283  meta_loss: 1.2291  hLoss: 0.2082  rLoss: 0.2388  oError: 0.4726  conv: 0.4075  avgPre: 0.6147\n","Batch: [0394/0500]  training loss: 0.8321  meta_loss: 1.2545  hLoss: 0.2057  rLoss: 0.2389  oError: 0.4696  conv: 0.4103  avgPre: 0.6135\n","Batch: [0395/0500]  training loss: 0.8341  meta_loss: 1.3184  hLoss: 0.2052  rLoss: 0.2443  oError: 0.4792  conv: 0.4140  avgPre: 0.6089\n","Batch: [0396/0500]  training loss: 0.8344  meta_loss: 1.2471  hLoss: 0.2046  rLoss: 0.2438  oError: 0.4967  conv: 0.4145  avgPre: 0.6018\n","Batch: [0397/0500]  training loss: 0.8357  meta_loss: 1.2734  hLoss: 0.2097  rLoss: 0.2428  oError: 0.4726  conv: 0.4156  avgPre: 0.6098\n","Batch: [0398/0500]  training loss: 0.8401  meta_loss: 1.3027  hLoss: 0.2098  rLoss: 0.2371  oError: 0.4543  conv: 0.4079  avgPre: 0.6200\n","Batch: [0399/0500]  training loss: 0.8327  meta_loss: 1.2250  hLoss: 0.2060  rLoss: 0.2400  oError: 0.4638  conv: 0.4109  avgPre: 0.6151\n","Batch: [0400/0500]  training loss: 0.8279  meta_loss: 1.2565  hLoss: 0.2072  rLoss: 0.2355  oError: 0.4579  conv: 0.4071  avgPre: 0.6213\n","Batch: [0401/0500]  training loss: 0.8240  meta_loss: 1.2086  hLoss: 0.2066  rLoss: 0.2373  oError: 0.4579  conv: 0.4081  avgPre: 0.6182\n","Batch: [0402/0500]  training loss: 0.8238  meta_loss: 1.1997  hLoss: 0.2083  rLoss: 0.2397  oError: 0.4682  conv: 0.4112  avgPre: 0.6129\n","Batch: [0403/0500]  training loss: 0.8244  meta_loss: 1.2572  hLoss: 0.2060  rLoss: 0.2353  oError: 0.4718  conv: 0.4024  avgPre: 0.6185\n","Batch: [0404/0500]  training loss: 0.8247  meta_loss: 1.2690  hLoss: 0.2078  rLoss: 0.2377  oError: 0.4389  conv: 0.4138  avgPre: 0.6255\n","Batch: [0405/0500]  training loss: 0.8276  meta_loss: 1.3201  hLoss: 0.2074  rLoss: 0.2398  oError: 0.4799  conv: 0.4096  avgPre: 0.6078\n","Batch: [0406/0500]  training loss: 0.8259  meta_loss: 1.2599  hLoss: 0.2053  rLoss: 0.2365  oError: 0.4748  conv: 0.4060  avgPre: 0.6162\n","Batch: [0407/0500]  training loss: 0.8257  meta_loss: 1.2281  hLoss: 0.2061  rLoss: 0.2421  oError: 0.4557  conv: 0.4155  avgPre: 0.6144\n","Batch: [0408/0500]  training loss: 0.8253  meta_loss: 1.3008  hLoss: 0.2079  rLoss: 0.2396  oError: 0.4638  conv: 0.4127  avgPre: 0.6132\n","Batch: [0409/0500]  training loss: 0.8250  meta_loss: 1.2789  hLoss: 0.2044  rLoss: 0.2381  oError: 0.4850  conv: 0.4058  avgPre: 0.6096\n","Batch: [0410/0500]  training loss: 0.8220  meta_loss: 1.2896  hLoss: 0.2055  rLoss: 0.2416  oError: 0.4696  conv: 0.4136  avgPre: 0.6104\n","Batch: [0411/0500]  training loss: 0.8244  meta_loss: 1.2936  hLoss: 0.2066  rLoss: 0.2427  oError: 0.4696  conv: 0.4138  avgPre: 0.6103\n","Batch: [0412/0500]  training loss: 0.8246  meta_loss: 1.2533  hLoss: 0.2075  rLoss: 0.2351  oError: 0.4287  conv: 0.4067  avgPre: 0.6345\n","Batch: [0413/0500]  training loss: 0.8219  meta_loss: 1.3306  hLoss: 0.2088  rLoss: 0.2351  oError: 0.4572  conv: 0.4041  avgPre: 0.6209\n","Batch: [0414/0500]  training loss: 0.8210  meta_loss: 1.2824  hLoss: 0.2094  rLoss: 0.2342  oError: 0.4572  conv: 0.4023  avgPre: 0.6222\n","Batch: [0415/0500]  training loss: 0.8229  meta_loss: 1.2783  hLoss: 0.2076  rLoss: 0.2372  oError: 0.4813  conv: 0.4067  avgPre: 0.6112\n","Batch: [0416/0500]  training loss: 0.8239  meta_loss: 1.2977  hLoss: 0.2054  rLoss: 0.2382  oError: 0.4726  conv: 0.4071  avgPre: 0.6127\n","Batch: [0417/0500]  training loss: 0.8225  meta_loss: 1.2876  hLoss: 0.2054  rLoss: 0.2375  oError: 0.4653  conv: 0.4055  avgPre: 0.6203\n","Batch: [0418/0500]  training loss: 0.8242  meta_loss: 1.2911  hLoss: 0.2004  rLoss: 0.2463  oError: 0.4689  conv: 0.4163  avgPre: 0.6099\n","Batch: [0419/0500]  training loss: 0.8278  meta_loss: 1.3506  hLoss: 0.2088  rLoss: 0.2360  oError: 0.4572  conv: 0.4066  avgPre: 0.6226\n","Batch: [0420/0500]  training loss: 0.8262  meta_loss: 1.2808  hLoss: 0.2085  rLoss: 0.2357  oError: 0.4572  conv: 0.4061  avgPre: 0.6205\n","Batch: [0421/0500]  training loss: 0.8271  meta_loss: 1.2930  hLoss: 0.2097  rLoss: 0.2343  oError: 0.4177  conv: 0.4069  avgPre: 0.6347\n","Batch: [0422/0500]  training loss: 0.8269  meta_loss: 1.2308  hLoss: 0.2061  rLoss: 0.2389  oError: 0.4718  conv: 0.4087  avgPre: 0.6136\n","Batch: [0423/0500]  training loss: 0.8257  meta_loss: 1.2968  hLoss: 0.2055  rLoss: 0.2367  oError: 0.4726  conv: 0.4061  avgPre: 0.6142\n","Batch: [0424/0500]  training loss: 0.8273  meta_loss: 1.2212  hLoss: 0.1951  rLoss: 0.2484  oError: 0.4389  conv: 0.4210  avgPre: 0.6128\n","Batch: [0425/0500]  training loss: 0.8312  meta_loss: 1.3812  hLoss: 0.2074  rLoss: 0.2367  oError: 0.4718  conv: 0.4065  avgPre: 0.6165\n","Batch: [0426/0500]  training loss: 0.8238  meta_loss: 1.1749  hLoss: 0.2071  rLoss: 0.2354  oError: 0.4587  conv: 0.4064  avgPre: 0.6207\n","Batch: [0427/0500]  training loss: 0.8233  meta_loss: 1.1979  hLoss: 0.2079  rLoss: 0.2344  oError: 0.4550  conv: 0.4022  avgPre: 0.6239\n","Batch: [0428/0500]  training loss: 0.8260  meta_loss: 1.2495  hLoss: 0.2042  rLoss: 0.2369  oError: 0.4667  conv: 0.4068  avgPre: 0.6161\n","Batch: [0429/0500]  training loss: 0.8238  meta_loss: 1.3039  hLoss: 0.2088  rLoss: 0.2310  oError: 0.4389  conv: 0.3999  avgPre: 0.6307\n","Batch: [0430/0500]  training loss: 0.8238  meta_loss: 1.2302  hLoss: 0.2060  rLoss: 0.2407  oError: 0.4543  conv: 0.4105  avgPre: 0.6186\n","Batch: [0431/0500]  training loss: 0.8238  meta_loss: 1.2286  hLoss: 0.2072  rLoss: 0.2333  oError: 0.4550  conv: 0.4017  avgPre: 0.6213\n","Batch: [0432/0500]  training loss: 0.8252  meta_loss: 1.2646  hLoss: 0.2074  rLoss: 0.2367  oError: 0.4433  conv: 0.4089  avgPre: 0.6234\n","Batch: [0433/0500]  training loss: 0.8297  meta_loss: 1.3180  hLoss: 0.2077  rLoss: 0.2364  oError: 0.4514  conv: 0.4107  avgPre: 0.6216\n","Batch: [0434/0500]  training loss: 0.8300  meta_loss: 1.1928  hLoss: 0.2068  rLoss: 0.2351  oError: 0.4535  conv: 0.4039  avgPre: 0.6244\n","Batch: [0435/0500]  training loss: 0.8287  meta_loss: 1.2773  hLoss: 0.2097  rLoss: 0.2316  oError: 0.4455  conv: 0.4023  avgPre: 0.6262\n","Batch: [0436/0500]  training loss: 0.8291  meta_loss: 1.2427  hLoss: 0.2046  rLoss: 0.2418  oError: 0.4784  conv: 0.4111  avgPre: 0.6095\n","Batch: [0437/0500]  training loss: 0.8294  meta_loss: 1.2435  hLoss: 0.2064  rLoss: 0.2364  oError: 0.4616  conv: 0.4037  avgPre: 0.6214\n","Batch: [0438/0500]  training loss: 0.8303  meta_loss: 1.3114  hLoss: 0.2090  rLoss: 0.2324  oError: 0.4572  conv: 0.3999  avgPre: 0.6241\n","Batch: [0439/0500]  training loss: 0.8324  meta_loss: 1.2386  hLoss: 0.2064  rLoss: 0.2374  oError: 0.4660  conv: 0.4082  avgPre: 0.6147\n","Batch: [0440/0500]  training loss: 0.8398  meta_loss: 1.3603  hLoss: 0.2048  rLoss: 0.2380  oError: 0.4492  conv: 0.4067  avgPre: 0.6230\n","Batch: [0441/0500]  training loss: 0.8330  meta_loss: 1.2674  hLoss: 0.2078  rLoss: 0.2368  oError: 0.4543  conv: 0.4122  avgPre: 0.6177\n","Batch: [0442/0500]  training loss: 0.8322  meta_loss: 1.2786  hLoss: 0.2075  rLoss: 0.2366  oError: 0.4748  conv: 0.4096  avgPre: 0.6117\n","Batch: [0443/0500]  training loss: 0.8317  meta_loss: 1.2898  hLoss: 0.2080  rLoss: 0.2342  oError: 0.4587  conv: 0.4057  avgPre: 0.6226\n","Batch: [0444/0500]  training loss: 0.8330  meta_loss: 1.2128  hLoss: 0.2077  rLoss: 0.2385  oError: 0.4696  conv: 0.4099  avgPre: 0.6153\n","Batch: [0445/0500]  training loss: 0.8349  meta_loss: 1.2821  hLoss: 0.2057  rLoss: 0.2418  oError: 0.4653  conv: 0.4091  avgPre: 0.6177\n","Batch: [0446/0500]  training loss: 0.8366  meta_loss: 1.2346  hLoss: 0.2077  rLoss: 0.2334  oError: 0.4448  conv: 0.4063  avgPre: 0.6224\n","Batch: [0447/0500]  training loss: 0.8358  meta_loss: 1.2703  hLoss: 0.2107  rLoss: 0.2368  oError: 0.4177  conv: 0.4106  avgPre: 0.6305\n","Batch: [0448/0500]  training loss: 0.8337  meta_loss: 1.2315  hLoss: 0.2072  rLoss: 0.2357  oError: 0.4579  conv: 0.4074  avgPre: 0.6234\n","Batch: [0449/0500]  training loss: 0.8343  meta_loss: 1.2080  hLoss: 0.2044  rLoss: 0.2414  oError: 0.4813  conv: 0.4114  avgPre: 0.6108\n","Batch: [0450/0500]  training loss: 0.8327  meta_loss: 1.2488  hLoss: 0.2040  rLoss: 0.2420  oError: 0.4696  conv: 0.4103  avgPre: 0.6136\n","Batch: [0451/0500]  training loss: 0.8344  meta_loss: 1.3087  hLoss: 0.2086  rLoss: 0.2343  oError: 0.4535  conv: 0.4058  avgPre: 0.6225\n","Batch: [0452/0500]  training loss: 0.8313  meta_loss: 1.2355  hLoss: 0.2088  rLoss: 0.2445  oError: 0.4609  conv: 0.4166  avgPre: 0.6067\n","Batch: [0453/0500]  training loss: 0.8286  meta_loss: 1.1764  hLoss: 0.2054  rLoss: 0.2352  oError: 0.4748  conv: 0.4059  avgPre: 0.6139\n","Batch: [0454/0500]  training loss: 0.8251  meta_loss: 1.2511  hLoss: 0.2055  rLoss: 0.2339  oError: 0.4177  conv: 0.4068  avgPre: 0.6314\n","Batch: [0455/0500]  training loss: 0.8304  meta_loss: 1.2602  hLoss: 0.2048  rLoss: 0.2368  oError: 0.4674  conv: 0.4062  avgPre: 0.6159\n","Batch: [0456/0500]  training loss: 0.8334  meta_loss: 1.2730  hLoss: 0.2052  rLoss: 0.2402  oError: 0.4865  conv: 0.4120  avgPre: 0.6065\n","Batch: [0457/0500]  training loss: 0.8373  meta_loss: 1.3207  hLoss: 0.2058  rLoss: 0.2404  oError: 0.4726  conv: 0.4116  avgPre: 0.6109\n","Batch: [0458/0500]  training loss: 0.8287  meta_loss: 1.2102  hLoss: 0.2071  rLoss: 0.2408  oError: 0.4601  conv: 0.4117  avgPre: 0.6146\n","Batch: [0459/0500]  training loss: 0.8383  meta_loss: 1.3174  hLoss: 0.2123  rLoss: 0.2298  oError: 0.4309  conv: 0.3993  avgPre: 0.6328\n","Batch: [0460/0500]  training loss: 0.8331  meta_loss: 1.2157  hLoss: 0.2094  rLoss: 0.2354  oError: 0.4587  conv: 0.4071  avgPre: 0.6200\n","Batch: [0461/0500]  training loss: 0.8351  meta_loss: 1.2316  hLoss: 0.2099  rLoss: 0.2368  oError: 0.4587  conv: 0.4071  avgPre: 0.6181\n","Batch: [0462/0500]  training loss: 0.8327  meta_loss: 1.2528  hLoss: 0.2048  rLoss: 0.2413  oError: 0.4982  conv: 0.4096  avgPre: 0.6029\n","Batch: [0463/0500]  training loss: 0.8324  meta_loss: 1.2394  hLoss: 0.2080  rLoss: 0.2388  oError: 0.4440  conv: 0.4140  avgPre: 0.6203\n","Batch: [0464/0500]  training loss: 0.8313  meta_loss: 1.2602  hLoss: 0.2062  rLoss: 0.2360  oError: 0.4718  conv: 0.4051  avgPre: 0.6176\n","Batch: [0465/0500]  training loss: 0.8262  meta_loss: 1.2197  hLoss: 0.2071  rLoss: 0.2397  oError: 0.4594  conv: 0.4115  avgPre: 0.6171\n","Batch: [0466/0500]  training loss: 0.8270  meta_loss: 1.2200  hLoss: 0.2078  rLoss: 0.2331  oError: 0.4623  conv: 0.4038  avgPre: 0.6219\n","Batch: [0467/0500]  training loss: 0.8252  meta_loss: 1.1871  hLoss: 0.2046  rLoss: 0.2382  oError: 0.4638  conv: 0.4118  avgPre: 0.6138\n","Batch: [0468/0500]  training loss: 0.8286  meta_loss: 1.2641  hLoss: 0.2074  rLoss: 0.2340  oError: 0.4784  conv: 0.4027  avgPre: 0.6153\n","Batch: [0469/0500]  training loss: 0.8285  meta_loss: 1.2252  hLoss: 0.2081  rLoss: 0.2327  oError: 0.4521  conv: 0.4037  avgPre: 0.6244\n","Batch: [0470/0500]  training loss: 0.8294  meta_loss: 1.2663  hLoss: 0.2086  rLoss: 0.2337  oError: 0.4543  conv: 0.4043  avgPre: 0.6248\n","Batch: [0471/0500]  training loss: 0.8289  meta_loss: 1.2268  hLoss: 0.2072  rLoss: 0.2444  oError: 0.4557  conv: 0.4184  avgPre: 0.6122\n","Batch: [0472/0500]  training loss: 0.8311  meta_loss: 1.2946  hLoss: 0.2062  rLoss: 0.2397  oError: 0.4682  conv: 0.4130  avgPre: 0.6117\n","Batch: [0473/0500]  training loss: 0.8243  meta_loss: 1.2197  hLoss: 0.2054  rLoss: 0.2336  oError: 0.4579  conv: 0.4039  avgPre: 0.6206\n","Batch: [0474/0500]  training loss: 0.8227  meta_loss: 1.2482  hLoss: 0.2101  rLoss: 0.2381  oError: 0.4572  conv: 0.4075  avgPre: 0.6180\n","Batch: [0475/0500]  training loss: 0.8227  meta_loss: 1.2215  hLoss: 0.2053  rLoss: 0.2398  oError: 0.4557  conv: 0.4126  avgPre: 0.6156\n","Batch: [0476/0500]  training loss: 0.8249  meta_loss: 1.2448  hLoss: 0.2073  rLoss: 0.2335  oError: 0.4565  conv: 0.4055  avgPre: 0.6211\n","Batch: [0477/0500]  training loss: 0.8211  meta_loss: 1.2048  hLoss: 0.2095  rLoss: 0.2333  oError: 0.4338  conv: 0.4004  avgPre: 0.6314\n","Batch: [0478/0500]  training loss: 0.8268  meta_loss: 1.3085  hLoss: 0.2084  rLoss: 0.2393  oError: 0.4579  conv: 0.4095  avgPre: 0.6149\n","Batch: [0479/0500]  training loss: 0.8339  meta_loss: 1.3183  hLoss: 0.2099  rLoss: 0.2349  oError: 0.4521  conv: 0.4075  avgPre: 0.6217\n","Batch: [0480/0500]  training loss: 0.8288  meta_loss: 1.2251  hLoss: 0.2086  rLoss: 0.2342  oError: 0.4550  conv: 0.4063  avgPre: 0.6237\n","Batch: [0481/0500]  training loss: 0.8337  meta_loss: 1.3163  hLoss: 0.2090  rLoss: 0.2358  oError: 0.4579  conv: 0.4074  avgPre: 0.6233\n","Batch: [0482/0500]  training loss: 0.8310  meta_loss: 1.2734  hLoss: 0.2077  rLoss: 0.2328  oError: 0.4609  conv: 0.4023  avgPre: 0.6211\n","Batch: [0483/0500]  training loss: 0.8270  meta_loss: 1.1928  hLoss: 0.2056  rLoss: 0.2351  oError: 0.4448  conv: 0.4049  avgPre: 0.6232\n","Batch: [0484/0500]  training loss: 0.8259  meta_loss: 1.2531  hLoss: 0.2072  rLoss: 0.2387  oError: 0.4682  conv: 0.4081  avgPre: 0.6137\n","Batch: [0485/0500]  training loss: 0.8287  meta_loss: 1.2526  hLoss: 0.2074  rLoss: 0.2345  oError: 0.4550  conv: 0.4090  avgPre: 0.6203\n","Batch: [0486/0500]  training loss: 0.8327  meta_loss: 1.2425  hLoss: 0.2051  rLoss: 0.2388  oError: 0.4857  conv: 0.4074  avgPre: 0.6101\n","Batch: [0487/0500]  training loss: 0.8326  meta_loss: 1.2513  hLoss: 0.2080  rLoss: 0.2399  oError: 0.4550  conv: 0.4142  avgPre: 0.6168\n","Batch: [0488/0500]  training loss: 0.8310  meta_loss: 1.2699  hLoss: 0.2068  rLoss: 0.2366  oError: 0.4221  conv: 0.4116  avgPre: 0.6264\n","Batch: [0489/0500]  training loss: 0.8322  meta_loss: 1.2492  hLoss: 0.2078  rLoss: 0.2363  oError: 0.4543  conv: 0.4067  avgPre: 0.6214\n","Batch: [0490/0500]  training loss: 0.8339  meta_loss: 1.3008  hLoss: 0.2103  rLoss: 0.2320  oError: 0.4521  conv: 0.4005  avgPre: 0.6260\n","Batch: [0491/0500]  training loss: 0.8334  meta_loss: 1.2489  hLoss: 0.2075  rLoss: 0.2335  oError: 0.4492  conv: 0.4067  avgPre: 0.6250\n","Batch: [0492/0500]  training loss: 0.8336  meta_loss: 1.2523  hLoss: 0.2067  rLoss: 0.2352  oError: 0.4587  conv: 0.4071  avgPre: 0.6209\n","Batch: [0493/0500]  training loss: 0.8345  meta_loss: 1.2540  hLoss: 0.2063  rLoss: 0.2403  oError: 0.4711  conv: 0.4104  avgPre: 0.6119\n","Batch: [0494/0500]  training loss: 0.8328  meta_loss: 1.2669  hLoss: 0.2073  rLoss: 0.2323  oError: 0.4587  conv: 0.4023  avgPre: 0.6227\n","Batch: [0495/0500]  training loss: 0.8313  meta_loss: 1.2508  hLoss: 0.2048  rLoss: 0.2370  oError: 0.4638  conv: 0.4088  avgPre: 0.6142\n","Batch: [0496/0500]  training loss: 0.8344  meta_loss: 1.2635  hLoss: 0.2051  rLoss: 0.2375  oError: 0.4638  conv: 0.4079  avgPre: 0.6186\n","Batch: [0497/0500]  training loss: 0.8336  meta_loss: 1.2976  hLoss: 0.2054  rLoss: 0.2382  oError: 0.4689  conv: 0.4065  avgPre: 0.6158\n","Batch: [0498/0500]  training loss: 0.8356  meta_loss: 1.2652  hLoss: 0.2062  rLoss: 0.2344  oError: 0.4565  conv: 0.4072  avgPre: 0.6222\n","Batch: [0499/0500]  training loss: 0.8370  meta_loss: 1.2400  hLoss: 0.2095  rLoss: 0.2324  oError: 0.4184  conv: 0.4081  avgPre: 0.6329\n","Batch: [0500/0500]  training loss: 0.8374  meta_loss: 1.2863  hLoss: 0.2071  rLoss: 0.2379  oError: 0.4616  conv: 0.4066  avgPre: 0.6175\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d9bce91611d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    363\u001b[0m                                                                                                   clean=False)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/creds_{str(i)}.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/predict_labels_{str(i)}.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../result/PML_MD/meta/music_emotion/0/true/1/creds_0.csv'"]}],"source":["import torch\n","import time\n","import os\n","import torch.optim as optim\n","import numpy as np\n","from model import LinearNet\n","from dataset import get_loader\n","from scipy.io import savemat\n","from criteria import hLoss, rLoss, oError, Conv, avgPre\n","\n","device = ('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","def TablePlot(df,w,h,outputPath):\n","    fig, ax = plt.subplots(figsize=(w,h))\n","    ax.axis('off')\n","    ax.table(\n","        df.values,\n","        #colLabels = df.columns,\n","        loc = 'center',\n","        bbox=[0,0,1,1],\n","        fontsize = 100\n","    )\n","    plt.savefig(outputPath)\n","    plt.show()\n","def criterion(predictions, confidence):\n","\n","    assert predictions.shape == confidence.shape\n","\n","    N, C = confidence.shape\n","\n","    loss_sum = torch.zeros(N, 1, dtype=torch.float, device=device)\n","\n","    ones = torch.ones_like(confidence, dtype=torch.float, device=device)\n","    zeros = torch.zeros_like(confidence, dtype=torch.float, device=device)\n","\n","    for i in range(C):\n","        confidence_i = confidence[:, i].view(N, -1)\n","        prediction_i = predictions[:, i].view(N, -1)\n","\n","        loss = torch.max(zeros, confidence_i - confidence) * torch.max(zeros, ones - (prediction_i - predictions))\n","        loss_sum += torch.sum(loss, dim=-1, keepdim=True) / ((C - 1) * 1.0)\n","\n","    return loss_sum.mean()\n","\n","def test(net, test_loader):\n","\n","    ######################################\n","    #信頼度のしきい値\n","    threshold = 0.8\n","    ######################################\n","\n","    net.eval()\n","\n","    hLoss_list = []\n","    rLoss_list = []\n","    oError_list = []\n","    conv_list = []\n","    avgPre_list = []\n","\n","    for itr, (inputs, labels) in enumerate(test_loader):\n","\n","        inputs = inputs.to(device)\n","        outputs = net(inputs)\n","        prelabel = (torch.sigmoid(outputs) > threshold).float()\n","\n","        hLoss_list.append(hLoss(outputs, labels))\n","        rLoss_list.append(rLoss(outputs, labels))\n","        oError_list.append(oError(outputs, labels))\n","        conv_list.append(Conv(outputs, labels))\n","        avgPre_list.append(avgPre(outputs, labels))\n","\n","    hamming_loss = np.mean(hLoss_list)\n","    ranking_loss = np.mean(rLoss_list)\n","    one_error = np.mean(oError_list)\n","    coverage = np.mean(conv_list)\n","    avg_precision = np.mean(avgPre_list)\n","\n","    return hamming_loss, ranking_loss, one_error, coverage, avg_precision, outputs.cpu().detach().numpy() ,prelabel.cpu().numpy()\n","\n","def train_common(net, optimizer, train_loader):\n","    train_loss = 0\n","\n","    for batch_idx, (inputs, labels) in enumerate(train_loader):\n","        net.train()\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    return train_loss\n","\n","def train_meta(net, optimizer, train_loader, meta_loader):\n","    train_loss = 0.0\n","    meta_loss = 0.0\n","    clean_iter = iter(meta_loader)\n","    for batch_idx, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        meta_net = LinearNet(num_inputs=features_num, num_outputs=labels_num)\n","        meta_net.load_state_dict(net.state_dict())\n","        meta_net.to(device)\n","        epsilon = torch.zeros_like(labels, requires_grad=True)\n","\n","        y_f_hat = meta_net(inputs)\n","        l_f_meta = criterion(y_f_hat, epsilon)\n","        meta_net.zero_grad()\n","\n","        grads = torch.autograd.grad(l_f_meta, (meta_net.params()), create_graph=True)\n","        meta_net.update_params(lr, source_params=grads)\n","\n","        try:\n","            val_data, val_labels = next(clean_iter)\n","        except StopIteration:\n","            clean_iter = iter(meta_loader)\n","            val_data, val_labels = next(clean_iter)\n","\n","        val_data, val_labels = val_data.to(device), val_labels.to(device)\n","\n","        y_g_hat = meta_net(val_data)\n","        l_g_meta = criterion(y_g_hat, val_labels)\n","\n","        grad_eps = torch.autograd.grad(l_g_meta, epsilon, only_inputs=True)[0]\n","\n","        # computing and normalizing the confidence matrix P\n","        # p_tilde = torch.clamp(epsilon - grad_eps, min=0)\n","        p_tilde = torch.clamp(-grad_eps, min=0)\n","        p_tilde *= labels\n","\n","        max_row = torch.max(p_tilde, dim=1, keepdim=True)[0]\n","        ones = torch.ones_like(max_row)\n","        max_row = torch.where(max_row == 0, ones, max_row)\n","        p = p_tilde / max_row\n","\n","        y_f_hat = net(inputs)\n","        l_f = criterion(y_f_hat, p)\n","\n","        optimizer.zero_grad()\n","        l_f.backward()\n","        optimizer.step()\n","\n","        meta_loss += l_g_meta.item()\n","        train_loss += l_f.item()\n","\n","    return meta_loss, train_loss\n","\n","\n","def baseline(train_loader, test_loader, meta_loader, num_epoch=500, clean=True):\n","    # method = baseline for baseline with meta data, else for baseline without meta data and ground-truth\n","\n","    net = LinearNet(num_inputs=features_num, num_outputs=labels_num)\n","    net = net.to(device)\n","    optimizer = optim.SGD(params=net.params(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n","\n","    hLoss_list = []\n","    rLoss_list = []\n","    oError_list = []\n","    conv_list = []\n","    avgPre_list = []\n","\n","    for epoch in range(num_epoch):\n","        loss = 0.0\n","        # adjust_learning_rate(optimizer, epoch, lr)\n","        if clean:\n","            loss += train_common(net, optimizer, meta_loader)\n","            loss += train_common(net, optimizer, train_loader)\n","            loss /= (len(meta_loader) + len(train_loader))\n","        else:\n","            loss += train_common(net, optimizer, train_loader)\n","            loss /= len(train_loader)\n","\n","        hamming_loss, ranking_loss, one_error, coverage, avg_precision, outputs, p_labels = test(net, test_loader)\n","\n","        print('Batch: [{:0>4}/{:0>4}] '.format(epoch + 1, num_epoch),\n","              'training loss: {:.4f} '.format(loss),\n","              'hLoss: {:.4f} '.format(hamming_loss),\n","              'rLoss: {:.4f} '.format(ranking_loss),\n","              'oError: {:.4f} '.format(one_error),\n","              'conv: {:.4f} '.format(coverage),\n","              'avgPre: {:.4f}'.format(avg_precision))\n","\n","        \"\"\"hLoss_list.append(hamming_loss)\n","        rLoss_list.append(ranking_loss)\n","        oError_list.append(one_error)\n","        conv_list.append(coverage)\n","        avgPre_list.append(avg_precision)\"\"\"\n","    #全エポックの中で最良の結果を返しているがそれはダメなので消した    \n","    #return np.min(hLoss_list), np.min(rLoss_list), np.min(oError_list), np.min(conv_list), np.max(avgPre_list)\n","    #最終的な結果と出力と予測ラベルを返す\n","    return hamming_loss, ranking_loss, one_error, coverage, avg_precision, outputs, p_labels\n","\n","def metalearning(train_loader, test_loader, meta_loader, num_epoch=500, clean=True):\n","\n","    net = LinearNet(num_inputs=features_num, num_outputs=labels_num)\n","    net = net.to(device)\n","    optimizer = optim.SGD(params=net.params(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n","\n","    hLoss_list = []\n","    rLoss_list = []\n","    oError_list = []\n","    conv_list = []\n","    avgPre_list = []\n","\n","    for epoch in range(num_epoch):\n","        train_loss = 0.0\n","        meta_loss = 0.0\n","\n","        if clean:\n","            train_loss += train_common(net, optimizer, train_loader)\n","            train_l, meta_l = train_meta(net, optimizer, train_loader, meta_loader)\n","            train_loss += train_l\n","            meta_loss += meta_l\n","\n","            train_loss /= (len(train_loader) + len(meta_loader))\n","            meta_loss /= len(train_loader)\n","        else:\n","            train_l, meta_l = train_meta(net, optimizer, train_loader, meta_loader)\n","            train_loss += train_l\n","            meta_loss += meta_l\n","\n","            train_loss /= len(train_loader)\n","            meta_loss /= len(train_loader)\n","\n","        hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels= test(net, test_loader)\n","\n","        print('Batch: [{:0>4}/{:0>4}] '.format(epoch + 1, num_epoch),\n","              'training loss: {:.4f} '.format(train_loss),\n","              'meta_loss: {:.4f} '.format(meta_loss),\n","              'hLoss: {:.4f} '.format(hamming_loss),\n","              'rLoss: {:.4f} '.format(ranking_loss),\n","              'oError: {:.4f} '.format(one_error),\n","              'conv: {:.4f} '.format(coverage),\n","              'avgPre: {:.4f}'.format(avg_precision))\n","\n","        \"\"\"hLoss_list.append(hamming_loss)\n","        rLoss_list.append(ranking_loss)\n","        oError_list.append(one_error)\n","        conv_list.append(coverage)\n","        avgPre_list.append(avg_precision)\"\"\"\n","\n","    #全エポックの中で最良の結果を返しているがそれはダメなので消した    \n","    #return np.min(hLoss_list), np.min(rLoss_list), np.min(oError_list), np.min(conv_list), np.max(avgPre_list)\n","    #最終的な結果と出力と予測ラベルを返す\n","    return hamming_loss, ranking_loss, one_error, coverage, avg_precision, outputs, p_labels\n","\n","\n","def save_result(data, method, learning_rate, result):\n","    file = './result/LinearNet/' + data\n","    if not os.path.exists(file):\n","        os.mkdir(file)\n","    filename = './result/LinearNet/' + data + '/' + method + '_' + str(learning_rate) + '.mat'\n","    content = {}\n","\n","    content['result'] = result\n","    savemat(filename, content)\n","\n","def save_log(content, learning_rate):\n","    filename = './result/LinearNet/' + str(learning_rate) + '_log.txt'\n","    file = open(filename, 'a')\n","    file.write(content)\n","    file.close()\n","\n","def adjust_learning_rate(optimizer, epochs, learning_rate):\n","    lr = learning_rate * ((0.1 ** int(epochs >= 80)) * (0.1 ** int(epochs >= 100)))  # For WRN-28-10\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","dir = \"/content/drive/MyDrive/Colab Notebooks\"\n","batch_size = 100\n","meta_size = 5\n","#lr_list = [0.01, 0.001]\n","lr_list = [0.01]\n","momentum = 0.9\n","weight_decay = 1e-4\n","methods = ['meta', 'meat_clean', 'baseline', 'baseline_clean', 'ground_truth']\n","datasets = ['music_emotion', 'music_style','mirflickr','emotions','enron','CAL500','scene','genbase']\n","repeat = 1\n","#noise_list_m = [50,100,150]\n","noise_list_m = [50]\n","#true_list = [1,3,5,7,9]\n","true_list = [1]\n","if __name__ == '__main__':\n","\n","    #for data in datasets:\n","    for data in [\"music_emotion\"]:\n","        print('\\n')\n","\n","        if data in ['music_emotion', 'music_style']:\n","            batch_size = 200\n","        elif data in ['mirflickr', 'tmc', 'mediamill']:\n","            batch_size = 500\n","        elif data in ['CAL500', 'emotions','genbase']:\n","            batch_size = 50\n","\n","        if data in ['music_emotion', 'music_style','YeastBP']:\n","          noise_list = [0]\n","        elif data in ['emotions','enron','CAL500','scene','genbase']:\n","          noise_list = noise_list_m.copy()\n","\n","        for lr in lr_list:\n","            #for method in methods:\n","            #print('Dataname: {}\\t Methods: {}\\t Learning rate: {}'.format(data, method, lr))\n","            #result = np.empty((repeat, 5), dtype=np.float)\n","            for i in range(repeat):\n","                for p_noise in noise_list:\n","                  result = [[\"\"]*6 for l in range(31)]\n","                  result[0][0] = \"p_true\"\n","                  result[1][0] = \"hamming_loss\"\n","                  result[7][0] = \"ranking_loss\"\n","                  result[13][0] = \"one_error\"\n","                  result[19][0] = \"coverage\"\n","                  result[25][0] = \"average_precision\"\n","                  result[0][1] = 1\n","                  result[0][2] = 3\n","                  result[0][3] = 5\n","                  result[0][4] = 7\n","                  result[0][5] = 9\n","                  \"\"\"df = pd.DataFrame(result)\n","                  #df=df.style.hide_index()\n","                  outputpath = \"/content/drive/MyDrive/Colab Notebooks/result/PML_MD/\"+str(p_noise)+\".jpg\"\n","                  TablePlot(df,len(result[0]),len(result)+1,outputpath)\"\"\"\n","                  for m in range(1):\n","                      method = methods[m]\n","                      result[2+m][0]=method\n","                      result[8+m][0]=method\n","                      result[14+m][0]=method\n","                      result[20+m][0]=method\n","                      result[26+m][0]=method\n","                      for tru in range(len(true_list)):\n","                      #for p_true in true_list:\n","                          p_true = true_list[tru]\n","                          cv_num = i\n","                          print(f'data={data}/cv={str(i)}/p_noise={str(p_noise)}/p_true={str(p_true)}/method={method}\\n')\n","                          train_loader, test_loader, meta_loader, clean_loader, \\\n","                          noisy_loader, features_num, labels_num = get_loader(data, batch_size, cv_num,p_noise,p_true,meta_size=meta_size)\n","\n","                          if method == 'meta':\n","                              hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels = metalearning(train_loader,\n","                                                                                                      test_loader,\n","                                                                                                      meta_loader,\n","                                                                                                      clean=False)\n","                          elif method == 'meta_clean':\n","                              hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels = metalearning(train_loader,\n","                                                                                                      test_loader,\n","                                                                                                      meta_loader,\n","                                                                                                      clean=True)\n","                          elif method == 'baseline':\n","                              hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels = baseline(noisy_loader,\n","                                                                                                  test_loader, meta_loader,\n","                                                                                                  clean=False)\n","                          elif method == 'baseline_clean':\n","                             hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels = baseline(train_loader,\n","                                                                                                  test_loader, meta_loader,\n","                                                                                                  clean=True)\n","\n","                          elif method == 'ground_truth':           # ground truth\n","                              hamming_loss, ranking_loss, one_error, coverage, avg_precision ,outputs, p_labels = baseline(clean_loader,\n","                                                                                                  test_loader, meta_loader,\n","                                                                                                  clean=False)\n","\n","                          np.savetxt(f\"{dir}/result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/creds_{str(i)}.csv\",outputs,delimiter =',')\n","                          np.savetxt(f\"{dir}/result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/predict_labels_{str(i)}.csv\",p_labels,fmt='%d',delimiter=',')\n","\n","                          result[2+m][1+tru]=format(hamming_loss,\".4f\")\n","                          result[8+m][1+tru]=format(ranking_loss,\".4f\")\n","                          result[14+m][1+tru]=format(one_error,\".4f\")\n","                          result[20+m][1+tru]=format(coverage,\".4f\")\n","                          result[26+m][1+tru]=format(avg_precision,\".4f\")\n","\n","\n","                          print()\n","                          print('Test results of the last :\\t',\n","                              'Best hLoss: {:.4f} '.format(hamming_loss),\n","                              'Best rLoss: {:.4f} '.format(ranking_loss),\n","                              'Best oError: {:.4f} '.format(one_error),\n","                              'Best conv: {:.4f} '.format(coverage),\n","                              'Best avgPre: {:.4f} '.format(avg_precision))\n","\n","                          \"\"\"result_mean = np.mean(result, axis=0)\n","                          result_std = np.std(result, axis=0)\n","\n","                          content = time.strftime('%Y-%m-%d %H:%M:%S   ', time.localtime()) + \\\n","                                                  'Dataset: {:15}  '.format(data) + 'Method: {:15}  '.format(method) + \\\n","                                                  'Learning Rate: {:.4f} '.format(lr) + \\\n","                                                  'p_noise: {:.d}'.format(p_noise) + \\\n","                                                  'p_true:{.d}'.format(p_true) + \\\n","                                                  'hLoss: {:.4f}/{:.4f}  '.format(result_mean[0], result_std[0]) + \\\n","                                                  'rLoss: {:.4f}/{:.4f}  '.format(result_mean[1], result_std[1]) + \\\n","                                                  'oError: {:.4f}/{:.4f}  '.format(result_mean[2], result_std[2]) + \\\n","                                                  'conv: {:.4f}/{:.4f}  '.format(result_mean[3], result_std[3]) + \\\n","                                                  'avgPre: {:.4f}/{:.4f}\\n'.format(result_mean[4], result_std[4])\n","                          #print()\n","                          #print(content)\"\"\"\n","\n","                          #save_result(data, method, lr, result)\n","                          #save_log(content, lr)\n","                  \n","                  #save_fname = str(p_noise)+\".csv\"\n","                  #df = pd.DataFrame(result)\n","                  #df=df.style.hide_index()\n","                  #outputpath = \"/content/drive/MyDrive/Colab Notebooks/result/PML_MD/\"+str(p_noise)+\".jpg\"\n","                  #TablePlot(df,20,10,outputpath)\n","                  #import csv\n","                  #with open(\"/content/drive/MyDrive/Colab Notebooks/result/PML_MD/\"+str(p_noise)+\".csv\", 'w', newline='') as fl:\n","                  #    writer = csv.writer(fl)\n","                  #    writer.writerows(result)"]},{"cell_type":"code","source":["np.savetxt(f\"{dir}/result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/creds_{str(i)}.csv\",outputs,delimiter =',')\n","np.savetxt(f\"{dir}/result/PML_MD/{method}/{data}/{str(p_noise)}/true/{str(p_true)}/predict_labels_{str(i)}.csv\",p_labels,fmt='%d',delimiter=',')"],"metadata":{"id":"1mZhjcsUacqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir = \"/content/drive/MyDrive/Colab Notebooks\""],"metadata":{"id":"1V_Xq4SOO7kk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["methods = ['meta', 'meat_clean', 'baseline', 'baseline_clean', 'ground_truth']\n","datasetss = ['music_emotion', 'music_style','mirflickr','YeastBP','emotions','enron','CAL500','scene','genbase']\n","repeat = 1\n","noise_list = [50,100,150]\n","#noise_list = [50]\n","true_list = [1,3,5,7,9]\n","for method in methods:\n","  %mkdir {method}\n","  %cd {method}\n","  for data in datasetss:\n","    if data in ['music_emotion', 'music_style','mirflickr','YeastBP']:\n","      %mkdir {data}\n","      %cd {data}\n","      for n in [0]:\n","        %mkdir {str(n)}\n","        %cd {str(n)}\n","        %mkdir true\n","        %cd true\n","        for t in true_list:\n","          %mkdir {str(t)}\n","        %cd ..\n","        %cd ..\n","    else:\n","      %mkdir {data}\n","      %cd {data}\n","      for n in noise_list:\n","        %mkdir {str(n)}\n","        %cd {str(n)}\n","        %mkdir true\n","        %cd true\n","        for t in true_list:\n","          %mkdir {str(t)}\n","        %cd ..\n","        %cd ..\n","    %cd ..\n","  %cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8TZam6qPVwI","executionInfo":{"status":"ok","timestamp":1671183862300,"user_tz":-540,"elapsed":92031,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"1a5dc41b-a292-4fc9-9734-6c1f45176666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_emotion/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_style/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/mirflickr/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/YeastBP/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meta\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_emotion/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_style/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/mirflickr/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/YeastBP/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/meat_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_emotion/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_style/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/mirflickr/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/YeastBP/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_emotion/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_style/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/mirflickr/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/YeastBP/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/baseline_clean\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_emotion/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_emotion/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_emotion\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_style/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_style/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/music_style\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/mirflickr/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/mirflickr/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/mirflickr\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/YeastBP/0/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/YeastBP/0\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/YeastBP\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/emotions\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/enron\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/CAL500\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/scene\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/50/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/50\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/100/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/100\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/150/true\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase/150\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth/genbase\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD/ground_truth\n","/content/drive/MyDrive/Colab Notebooks/result/PML_MD\n"]}]},{"cell_type":"code","source":["from scipy.sparse import csr_matrix\n","from sklearn.metrics import hamming_loss, coverage_error, label_ranking_average_precision_score, label_ranking_loss\n","import numpy as np"],"metadata":{"id":"pRbusio_mZfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_list=[\"emotions\",\"enron\",\"CAL500\",\"scene\",\"genbase\",\"mirflickr\",\"music_style\",\"music_emotion\"]\n","for i in range(len(d_list)):\n","  dataname=d_list[i]\n","  ath = f\"/content/drive/MyDrive/Colab Notebooks/new_data2/\" + dataname + \"/\"\n","  labels = np.loadtxt(ath+\"target.csv\", delimiter=',',dtype =float)\n","  if dataname in [\"mirflickr\",\"music_style\",\"music_emotion\"]:\n","    plabels = np.loadtxt(ath+\"cand/0.csv\", delimiter=',',dtype =float)\n","  else:\n","    plabels = np.loadtxt(ath+\"cand/50.csv\", delimiter=',',dtype =float)\n","  a,b=np.shape(labels)\n","  z=np.zeros((a,b))\n","  o=np.ones((a,b))\n","  zl=coverage_error(labels,z)\n","  ol=coverage_error(labels,o)\n","  print(dataname)\n","  print(\"zl=\"+str(zl))\n","  print(\"ol=\"+str(ol))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGxWBHadk8gg","executionInfo":{"status":"ok","timestamp":1670890992100,"user_tz":-540,"elapsed":1162,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"040885ac-85e7-472d-ccb2-ddd24b7e3199"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["emotions\n","zl=6.0\n","ol=6.0\n","enron\n","zl=53.0\n","ol=53.0\n","CAL500\n","zl=174.0\n","ol=174.0\n","scene\n","zl=6.0\n","ol=6.0\n","genbase\n","zl=27.0\n","ol=27.0\n","mirflickr\n","zl=7.0\n","ol=7.0\n","music_style\n","zl=10.0\n","ol=10.0\n","music_emotion\n","zl=11.0\n","ol=11.0\n"]}]},{"cell_type":"code","source":["print(zl)\n","print(ol)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5vCUOPRumsAW","executionInfo":{"status":"ok","timestamp":1670869871633,"user_tz":-540,"elapsed":237,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"e701424b-9aa2-49af-a350-9142eb724db6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.22032116866011203\n","0.779678831339888\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP75kPV/82f1xsclnPhIQ4b"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}