{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnUQMtpumQrpPrDSMVmFmh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2d_Rf6A8qIr","executionInfo":{"status":"ok","timestamp":1669473861496,"user_tz":-540,"elapsed":17513,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"8a2644e6-33f2-4ee1-f2ed-c4804af69027"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Md4jAJ5cTsID","executionInfo":{"status":"ok","timestamp":1669473861496,"user_tz":-540,"elapsed":2,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"5faf5780-25ad-4811-ef9e-1cf068e4c8ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import scipy.io\n","from sklearn.metrics import hamming_loss\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/')\n","import metrics as mt\n","from sklearn.metrics import label_ranking_average_precision_score\n","from numpy import linalg as LA\n","from itertools import combinations\n","from scipy.linalg import norm\n","sys.path.append('./function')\n","import csv\n","from sklearn.preprocessing import MinMaxScaler\n"],"metadata":{"id":"eHYowTYI9mkE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["PML-NI用のデータの加工\n","\n","ラベル数を15に制限する"],"metadata":{"id":"IznI4oipdbzy"}},{"cell_type":"code","source":["def data_for_pmlni(data,candidate_labels,true_labels):\n","  [num_data,num_fea] = np.shape(data)\n","  [a,b] = np.shape(candidate_labels)\n","  if a != num_data:\n","    candidate_labels = candidate_labels.T\n","    true_labels = true_labels.T\n","    num_labels = a\n","  if num_labels > 100:\n","    labels_sum = np.zeros((1,num_labels))\n","    for i in range(0,num_data):\n","      for j in range(0,num_labels):\n","        if candidate_labels[i,j] == 1:\n","          labels_sum[0,j] += 1\n","    sum_label_rank_ind = np.argsort(labels_sum[0])\n","    new_cand_labels = np.zeros((num_data,15))\n","    new_true_labels = np.zeros((num_data,15))\n","    for i in range(0,15):\n","      new_cand_labels[:,i] = candidate_labels[:,-sum_label_rank_ind[i]-1]\n","      new_true_labels[:,i] = true_labels[:,-sum_label_rank_ind[i]-1]\n","    delete_ind = np.array([],dtype = 'int')\n","    for i in range(0,num_data):\n","      a = 0\n","      for j in range(0,15):\n","        if new_cand_labels[i,j] == 1:\n","          a = 1\n","      if a == 0:\n","        delete_ind = np.append(delete_ind,i)\n","    for i in range(0,len(delete_ind)):\n","      data = np.delete(data,delete_ind[-i-1],0)\n","      new_cand_labels = np.delete(new_cand_labels,delete_ind[-i-1],0)\n","      new_true_labels = np.delete(new_true_labels,delete_ind[-i-1],0)\n","    return(data,new_cand_labels.T,new_true_labels.T)\n","  else:\n","    return(data,candidate_labels.T,true_labels.T)"],"metadata":{"id":"ljROIthQCHMz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PMLNI:\n","  def __init__(self):\n","    self.lambd = 10\n","    self.beta = 0.5\n","    self.gamma = 0.5\n","    self.max_iter = 500\n","\n","  # train_data:M*D (num_data * num_feature)\n","  # train_target:M*Q (num_label * num_data)\n","  # true_target:M*Q (num_label * num_data)\n","  # test_data:N*D (num_data * num_feature)\n","  def fit(self,train_data,train_target,true_target,test_data):\n","    lambd = self.lambd\n","    beta = self.beta\n","    gamma = self.gamma\n","    max_iter = self.max_iter\n","\n","    train_target_T = train_target\n","    true_target_T = true_target\n","    train_target = train_target_T.T\n","    true_target = true_target_T.T\n","    [num_train,dim] = np.shape(train_data)\n","    [num_label,a] = np.shape(train_target)\n","    ##Training\n","    fea_matrix = np.concatenate([train_data,np.ones((num_train,1))],1)\n","    U = np.zeros((num_label,dim+1))\n","    V = np.zeros((num_label,dim+1))\n","    Y = np.zeros((num_label,dim+1))\n","    mu = 1e-4\n","    rho = 1.1\n","\n","    YX = train_target @ fea_matrix\n","    XX = fea_matrix.T @ fea_matrix\n","\n","    for t in range(0,max_iter):\n","      # update W\n","      \n","      # W = (YX+(mu*U)+(mu*V)+Y)/(XX+(lambd+mu)*np.eye(dim+1))\n","      A = YX+(mu*U)+(mu*V)+Y\n","      B = XX+(lambd+mu)*np.eye(dim+1)\n","      W = np.linalg.lstsq(B.T,A.T)[0].T\n","      #W = np.matmul(A,np.linalg.inv(B))\n","      #W = dot(A, np.linalg.pinv(B)) \n","\n","      # update U V\n","      Uk = np.copy(U)\n","      Vk = np.copy(V)\n","      [M,s,Nhat] = np.linalg.svd(W-V-Y/mu, full_matrices=False)\n","      svp = len(np.where(s>beta/mu)[0])\n","      if svp >= 1:\n","        s = s[0:svp] - beta/mu\n","      else:\n","        svp = 1\n","        s = np.array([0])\n","      Uhat =M[:,0:svp] @ np.diag(s) @ Nhat[0:svp,:]\n","      U = np.copy(Uhat)\n","      \n","      #L1 NORM\n","      Vraw = W - U - Y/mu\n","      Vhat = np.zeros((num_label,dim+1))\n","      for i in range(0,num_label):\n","        for j in range(0,dim+1):\n","          Vhat[i,j] = max(Vraw[i,j]-gamma/mu,0) + min(Vraw[i,j]+gamma/mu,0)\n","      \n","      '''# L2,1 NORM\n","      Vraw = W - U - Y/mu\n","      Vhat = np.zeros((num_label,dim+1))\n","      for j in range(0,num_label):\n","        v = Vraw[j,:]\n","        vNorm = norm(v)\n","        if vNorm > gamma/mu:\n","          Vhat[j,:] = (vNorm-gamma/mu) / vNorm * v'''\n","      V = np.copy(Vhat)\n","\n","      # stop criterion\n","      convg2 = False\n","      stopCriterion2 = mu*LA.norm(U-Uk,'fro')/LA.norm(W,'fro')\n","      if stopCriterion2 < 1e-5:\n","        convg2=True\n","      convg1 = False\n","      tmp = W - U - V\n","      stopCriterion1 = LA.norm(tmp,'fro')/LA.norm(W,'fro')\n","      if stopCriterion1 < 1e-7:\n","        convg1 = True\n","      if convg2:\n","        mu = min(rho*mu,1e10)\n","      Y = Y + mu*(U+V-W)\n","\n","      if convg1 and convg2:\n","        break\n","    \n","    # Computing the size predictor using linear least squares model\n","    # しきい値の予測器の計算\n","    Outputs = fea_matrix @ U.T # M*Q\n","    Left = Outputs\n","    Right = np.zeros((num_train,1)) # M*1\n","    for i in range(0,num_train):\n","      temp = Left[i,:]\n","      index = np.argsort(temp)\n","      temp_sorted = np.sort(temp)\n","      candidate = np.zeros((1,num_label + 1))\n","      candidate[0,0] = temp[0]-0.1\n","      for j in range(0,num_label-1):\n","        candidate[0,j+1] = (temp_sorted[j]+temp_sorted[j+1])/2\n","      candidate[0,num_label] = temp_sorted[num_label - 1] + 0.1\n","      miss_class = np.zeros((1,num_label+1))\n","      for j in range(0,num_label+1):\n","        temp_notlabels = index[:j]\n","        temp_labels = index[j:]\n","        notlabels_true_target = np.ravel(np.where(true_target_T[i,:] != 1))\n","        labels_true_target = np.ravel(np.where(true_target_T[i,:] == 1))\n","        false_neg = len(np.array(list(set(temp_notlabels)-set(notlabels_true_target))))\n","        false_pos = len(np.array(list(set(temp_labels)-set(labels_true_target))))\n","        miss_class[0,j] = false_neg + false_pos\n","      temp_index = np.argmin(miss_class)\n","      Right[i,0] = candidate[0,temp_index]\n","    Left = np.concatenate([Left,np.ones((num_train,1))],1)\n","\n","    # for matlab : tempvalue = (Left\\Right).T\n","    tempvalue = np.linalg.lstsq(Left, Right)[0]\n","    #tempvalue = np.linalg.solve(A,B)\n","    \"\"\"num_vars = Left.shape[1]\n","    rank = np.linalg.matrix_rank(Left)\n","    print(rank)\n","    print(num_vars)\n","    if rank == num_vars:\n","        tempvalue = np.linalg.lstsq(Left, Right)[0]    # not under-determined\n","    else:\n","        for nz in combinations(range(num_vars), rank):    # the variables not set to zero\n","            try: \n","                tempvalue = np.zeros((num_vars, 1))  \n","                tempvalue[nz, :] = np.asarray(np.linalg.solve(Left[:, nz], Right))\n","            except np.linalg.LinAlgError:     \n","                pass\"\"\"\n","    Weights_sizepre = tempvalue[0:num_label]\n","    Bias_sizepre = tempvalue[num_label:]\n","\n","    #compute Treshold for each test data\n","    [num_test, a] = np.shape(test_data)\n","    Outputs = np.concatenate([test_data,np.ones((num_test,1))],1) @ U.T\n","    WX = test_data @ U[:,:-1].T\n","    Threshold = np.concatenate([WX,np.ones((num_test,1))],1) @ np.concatenate([Weights_sizepre,Bias_sizepre])\n","\n","    # compute result\n","    Pre_Labels = np.zeros((num_test,num_label))\n","    for i in range(0,num_test):\n","      for k in range(0,num_label):\n","        if Outputs[i,k] >= Threshold[i,0]:\n","          Pre_Labels[i,k] = 1\n","        else:\n","          Pre_Labels[i,k] = 0\n","    \n","    self.Outputs = Outputs\n","    self.Labels = Pre_Labels\n","\n","  def outputs(self):\n","    return(self.Outputs)\n","\n","  def predict(self):\n","    return(self.Labels)"],"metadata":{"id":"kER_uY2w8mwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from liblinear.python.liblinear.liblinearutil import *\n","from PML_NI import PML_NI\n","#import multilabel_knn.multilabel_knn as mlk\n","def functions(train_data,train_target,true_target,test_data,test_target,mode):\n","  if mode == 0: ## PML_NI\n","    clf = PMLNI()\n","    clf.fit(train_data,train_target,true_target,test_data)\n","    print(\"finish PMLNI_fit\")\n","    creds = clf.outputs()\n","    print(\"finish get creds\")\n","    predict_labels = clf.predict()\n","    print(\"finish get p_labs\")\n","  elif mode == 1: ## ML_kNN\n","    model = mlk.multilabel_kNN(k=3, metric = \"euclidean\") #k: number of neighbors, metric: distance metric {\"euclidean\", \"cosine\"}\n","    model.fit(train_data, train_target) # X :2d feature vectors. Y: label matrix, where Y[i,k] = 1 if i has label k.\n","    predict_labels = model.predict(test_data).toarray() # X :2d feature vectors. Y: label matrix, where Y[i,k] = 1 if i has label k.\n","    creds = model.predict(test_data, return_prob = True)[1].toarray()\n","  elif mode == 2:\n","    train_target_T = np.array(train_target).T\n","    test_target_T = np.array(test_target).T\n","    [num_label,num_train] = np.shape(train_target_T)\n","    [num_test,num_fea] = np.shape(test_data)\n","    #%cd /content/drive/My Drive/Colab Notebooks/function/liblinear-2.45\n","    creds = np.zeros((num_label,num_test))\n","    predict_labels = np.zeros((num_label,num_test))\n","    for i in range(0,num_label):\n","      y_train = train_target_T[i]\n","      y_test = test_target_T[i]\n","      m = train(y_train, train_data)\n","      p_label, p_acc, p_val = predict(y_test, test_data, m)\n","      predict_labels[i] = np.array(p_label)\n","      creds[i] = np.ravel(np.array(p_val))\n","  return(creds,predict_labels)\n","\n","def get_cvdata(data,candidate_labels,target,crossval_ind,cv_num):\n","  train_data = []\n","  train_target = []\n","  true_target = []\n","  test_data = []\n","  test_target = []\n","  for j in range(0,5):\n","    if cv_num != j:\n","      for k in range(0,len(crossval_ind[j])):\n","        train_data.append(data[crossval_ind[j][k],:])\n","        train_target.append(candidate_labels[crossval_ind[j][k],:])\n","        true_target.append(target[crossval_ind[j][k],:])\n","    elif cv_num == j:\n","      for k in range(0,len(crossval_ind[j])):\n","        test_data.append(data[crossval_ind[j][k],:])\n","        test_target.append(target[crossval_ind[j][k],:])\n","  train_data = np.array(train_data)\n","  train_target = np.array(train_target)\n","  true_target = np.array(true_target)\n","  test_data = np.array(test_data)\n","  test_target = np.array(test_target)\n","  return(train_data,train_target,true_target,test_data,test_target)\n","\n","def save_result(kind_of_data,creds,predict_labels,mode,percent_of_noise,cv_num):\n","  func_list = [\"PML_NI\",\"ML_kNN\",\"BR\"]\n","  dir_name = \"./result/\"+str(func_list[mode])+\"/\"+str(kind_of_data)+\"/\"+str(percent_of_noise)\n","  np.savetxt(dir_name+\"/creds_\"+str(cv_num)+\".csv\",creds,delimiter=\",\")\n","  np.savetxt(dir_name+\"/predict_labels_\"+str(cv_num)+\".csv\",predict_labels,fmt=\"%d\",delimiter=\",\")"],"metadata":{"id":"CHk6rVbQTftw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_list = list([[\"emotions\",\"enron\",\"CAL500\",\"scene\",\"genbase\"],[\"mirflickr\",\"music_style\",\"music_emotion\"],[\"YeastBP\"]])\n","percent_of_true = 0"],"metadata":{"id":"kV7itNpuTM6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(1):\n","  for j in range(1,2):\n","  #for j in range(1,len(data_list[i])): # kind_of_data\n","    kind_of_data = data_list[i][j]\n","    percent_of_noise = 0\n","    data_fname = kind_of_data + \"_data_0_0.csv\"\n","    \n","    pre_data = np.loadtxt(\"./datas/\"+str(kind_of_data)+\"/0/\"+data_fname, delimiter=',')\n","    scaler = MinMaxScaler(feature_range=(0,1))\n","    data = scaler.fit_transform(pre_data)\n","    #data = np.loadtxt(\"./datas/\"+str(kind_of_data)+\"/0/\"+data_fname, delimiter=',')\n","    target_fname = kind_of_data + \"_target_\" + str(percent_of_noise) + \"_\" + str(percent_of_true) +\".csv\"\n","    target = np.loadtxt(\"./datas/\"+str(kind_of_data)+\"/\"+str(percent_of_noise)+\"/\"+target_fname, delimiter=',')\n","    with open(\"./datas/\"+str(kind_of_data)+\"/cv_inds.csv\") as f:\n","      reader = csv.reader(f)\n","      r = [row for row in reader]\n","      crossval_ind = [[int(v) for v in row] for row in r]\n","      del r\n","    f.close()\n","    \n","    for cv_num in range(1): # cross validation\n","      if i == 0:\n","        for l in range(0,1): # percent_of_noise\n","          percent_of_noise = (l+1)*50\n","          candidate_labels_fname = kind_of_data + \"_candidate_labels_\" + str(percent_of_noise)+\".csv\"\n","          candidate_labels = np.loadtxt(\"./datas/\"+str(kind_of_data)+\"/\"+str(percent_of_noise)+\"/\"+candidate_labels_fname, delimiter=',')\n","          train_data,train_target,true_target,test_data,test_target = get_cvdata(data,candidate_labels,target,crossval_ind,cv_num)\n","          for mode in range(1):\n","            print(\"start function\")\n","            creds,predict_labels = functions(train_data,train_target,true_target,test_data,test_target,mode)\n","            print(\"finish function\")\n","            save_result(kind_of_data,creds,predict_labels,mode,percent_of_noise,cv_num)\n","            print(\"finish save result\")\n","      elif i != 0:\n","        percent_of_noise = 0\n","        candidate_labels_fname = kind_of_data + \"_candidate_labels_\" + str(percent_of_noise) + \"_\" + str(percent_of_true) +\".csv\"\n","        candidate_labels = np.loadtxt(\"./datas/\"+str(kind_of_data)+\"/\"+str(percent_of_noise)+\"/\"+candidate_labels_fname, delimiter=',')\n","        train_data,train_target,true_target,test_data,test_target = get_cvdata(data,candidate_labels,target,crossval_ind,cv_num)\n","        for mode in range(0,1):\n","            creds,predict_labels = functions(train_data,train_target,true_target,test_data,test_target,mode)\n","            save_result(kind_of_data,creds,predict_labels,mode,percent_of_noise,cv_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFLePXdx8lBA","executionInfo":{"status":"ok","timestamp":1669477842532,"user_tz":-540,"elapsed":95191,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"d133254a-ca8d-4c26-c1b0-071c8ce5a263"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start function\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"]},{"output_type":"stream","name":"stdout","text":["finish PMLNI_fit\n","finish get creds\n","finish get p_labs\n","finish function\n","finish save result\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:120: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n","To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"]}]},{"cell_type":"code","source":["[aaa,bbb] = np.shape(creds)\n","indicater = 0\n","for i in range(aaa):\n","  for j in range(bbb):\n","    if creds[i][j] < 0:\n","      indicater += 1\n","print(indicater)\n","print(aaa*bbb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMv2mOrWaOmV","executionInfo":{"status":"ok","timestamp":1669477849851,"user_tz":-540,"elapsed":270,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"b10a3ad4-9ae9-4027-85b7-1eb708a68718"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5638\n","18073\n"]}]},{"cell_type":"markdown","source":["インスタンス数M、ラベル数Q\n","\n","creds:M*Q\n","\n","test_target:M*Q"],"metadata":{"id":"SATcRe9pojJX"}},{"cell_type":"code","source":["i = 0\n","result[i,0] = hamming_loss(test_target,predict_labels)\n","result[i,1] = mt.one_error(creds,test_target)\n","result[i,2] = mt.ranking_loss(creds,test_target)\n","result[i,3] = mt.coverage(creds,test_target)\n","result[i,4] = label_ranking_average_precision_score(test_target,creds)"],"metadata":{"id":"0etATyjT969K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7x-8xbC8xuj8","executionInfo":{"status":"ok","timestamp":1668402074251,"user_tz":-540,"elapsed":261,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"2e5b5cc8-3d32-49d2-ba62-171f0bb0f974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.81734993 0.37554905 0.15097304 0.30856515 0.71607467]\n"," [0.         0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":["print(test_target)\n","print(predict_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIotG_24Y5nZ","executionInfo":{"status":"ok","timestamp":1668402085862,"user_tz":-540,"elapsed":801,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"c2b1892d-d429-4797-e007-04eb33e570e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 1 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]]\n","[[1. 1. 1. ... 1. 1. 1.]\n"," [1. 1. 1. ... 1. 1. 1.]\n"," [1. 0. 1. ... 1. 1. 1.]\n"," ...\n"," [1. 1. 1. ... 1. 1. 1.]\n"," [1. 1. 1. ... 1. 1. 1.]\n"," [1. 1. 1. ... 1. 1. 1.]]\n"]}]},{"cell_type":"code","source":["a = np.array([9,8,7,6,5,4,3,2,1])\n","print(a[:4]-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jw3yXiOw5-ac","executionInfo":{"status":"ok","timestamp":1669382762302,"user_tz":-540,"elapsed":334,"user":{"displayName":"水口晴陽","userId":"02563633021533009649"}},"outputId":"ec19ada1-99b0-49bd-8f23-d69b66ea7a11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8 7 6 5]\n"]}]}]}